{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Scoringrules is a python library for evaluating probabilistic forecasts by computing scoring rules and other diagnostic quantities. It aims to assist forecasting practitioners by providing a set of tools based the scientific literature and via its didactic approach.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Fast computations of several probabilistic univariate and multivariate verification metrics</li> <li>Multiple backends: support for numpy (accelerated with numba), jax, pytorch and tensorflow</li> <li>Didactic approach to probabilistic forecast evaluation through clear code and documentation</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>Requires python <code>&gt;=3.10</code>!</p> <pre><code>pip install scoringrules\n</code></pre>"},{"location":"#quick-example","title":"Quick example","text":"<pre><code>import scoringrules as sr\nimport numpy as np\n\nobs = np.random.randn(100)\nfct = obs[:,None] + np.random.randn(100, 21) * 0.1\nsr.crps_ensemble(obs, fct)\n</code></pre>"},{"location":"#metrics","title":"Metrics","text":"<ul> <li>Brier Score</li> <li>Continuous Ranked Probability Score (CRPS)</li> <li>Logarithmic score</li> <li>Error Spread Score</li> <li>Energy Score</li> <li>Variogram Score</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you found this library useful for your own research, consider citing:</p> <pre><code>@software{zanetta_scoringrules_2024,\n  author = {Francesco Zanetta and Sam Allen},\n  title = {Scoringrules: a python library for probabilistic forecast evaluation},\n  year = {2024},\n  url = {https://github.com/frazane/scoringrules}\n}\n</code></pre>"},{"location":"#acknowledgements","title":"Acknowledgements","text":"<p>scoringRules served as a reference for this library. The authors did an outstanding work which greatly facilitated ours. The implementation of the ensemble-based metrics as jit-compiled numpy generalized <code>ufuncs</code> was first proposed in properscoring, released under Apache License, Version 2.0.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>We welcome contributions! You can help improve the library in many ways:</p> <ul> <li>Report issues or propose enhancements using on the GitHub issue tracker</li> <li>Improve or extend the codebase</li> <li>Improve or extend the documentation</li> </ul>"},{"location":"contributing/#getting-started","title":"Getting started","text":"<p>Fork the repository on GitHub and clone it to your computer:</p> <pre><code>git clone https://github.com/&lt;your-username&gt;/scoringrules.git\n</code></pre> <p>We use uv for project management and packaging. Install it with</p> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> <p>Then, you can install the library and all dependencies (including development dependencies) and  install the pre-commit hooks:</p> <pre><code>uv install\nuv run pre-commit install\n</code></pre> <p>From here you can work on your changes! Once you're satisfied with your changes, and followed the additional instructions below, push everything to your repository and open a pull request on GitHub.</p>"},{"location":"contributing/#contributing-to-the-codebase","title":"Contributing to the codebase","text":"<p>Don't forget to include new tests if necessary, then make sure that all tests are passing with</p> <pre><code>uv run pytest tests/\n</code></pre>"},{"location":"contributing/#contributing-to-the-documentation","title":"Contributing to the documentation","text":"<p>You can work on the documentation by modifying <code>mkdocs.yaml</code> and files in <code>docs/</code>. The most convenient way to do it is to run</p> <pre><code>uvx --with-requirements docs/requirements.txt mkdocs serve\n</code></pre> <p>and open the locally hosted documentation on your browser. It will be updated automatically every time you make changes and save. If you edit or add pieces of LaTex math, please make sure they are rendered correctly.</p>"},{"location":"crps_estimators/","title":"Crps estimators","text":"<p>(crps-estimators)=</p>"},{"location":"crps_estimators/#crps-estimators","title":"CRPS estimators","text":""},{"location":"crps_estimators/#integral-form-int","title":"Integral form (INT)","text":"<p>The numerical approximation of the cumulative integral over the finite ensemble.</p> <pre><code>:label: int\n\\text{CRPS}_{\\text{INT}}(M, y) = \\int_{\\mathbb{R}} \\left[ \\frac{1}{M}\n    \\sum_{i=1}^M \\mathbb{1}\\{x_i \\le x \\} - \\mathbb{1}\\{y \\le x\\}  \\right] ^2 dx\n</code></pre> <p>Runs with {math}<code>O(m\\cdot\\mathrm{log}m)</code> complexity, including the sorting of the ensemble.</p>"},{"location":"crps_estimators/#energy-form-nrg","title":"Energy form (NRG)","text":"<p>Introduced by Gneiting and Raftery (2007):</p> <p>.. $$ \\text{CRPS}{\\text{NRG}}(M, y) = \\frac{1}{M} \\sum{i=1}^{M}|x_i - y| - \\frac{1}{2 M^2}\\sum_{i,j=1}^{M}|x_i - x_j|$$</p> <p>..  It is called the \"energy form\" because it is the one-dimensional case of the Energy Score.</p> <p>.. Runs with \\(O(m^2)\\) complexity.</p> <p>.. # Quantile decomposition form (QD)</p> <p>.. Introduced by Jordan (2016)<sup>1</sup>:</p> <p>.. \\(\\(\\mathrm{CRPS}_{\\mathrm{QD}}(M, y) = \\frac{2}{M^2} \\sum_{i=1}^{M}(x_i - y)\\left[M\\mathbb{1}\\{y \\le x_i\\} - i + \\frac{1}{2} \\right]\\)\\)</p> <p>.. Runs with \\(O(m\\cdot\\mathrm{log}m)\\) complexity, including the sorting of the ensemble.</p> <p>.. # Probability weighted moment form (PWM)</p> <p>.. Introduced by Taillardat et al. (2016)<sup>2</sup>:</p> <p>.. \\(\\(\\mathrm{CRPS}_{\\mathrm{NRG}}(M, y) = \\frac{1}{M} \\sum_{i=1}^{M}|x_i - y| + \\hat{\\beta_0} - 2\\hat{\\beta_1},\\)\\)</p> <p>.. where \\(\\hat{\\beta_0} = \\frac{1}{M} \\sum_{i=1}^{M}x_i\\) and \\(\\hat{\\beta_1} = \\frac{1}{M(M-1)} \\sum_{i=1}^{M}(i - 1)x_i\\). Runs with \\(O(m\\cdot\\mathrm{log}m)\\) complexity, including the sorting of the ensemble. --&gt;</p> <p>.. _Gneiting and Raftery: Gneiting, T., &amp; Raftery, A. E. (2007).      Strictly proper scoring rules, prediction, and estimation.     Journal of the American statistical Association, 102(477), 359-378.</p> <ol> <li> <p>Alexander Jordan. Facets of forecast evaluation. PhD thesis, Karlsruher Institut f\u00fcr Technologie (KIT), 2016. doi:10.5445/IR/1000063629.\u00a0\u21a9</p> </li> <li> <p>Maxime Taillardat, Olivier Mestre, Micha\u00ebl Zamo, and Philippe Naveau. Calibrated Ensemble Forecasts Using Quantile Regression Forests and Ensemble Model Output Statistics. Monthly Weather Review, 2016. URL: http://journals.ametsoc.org/doi/10.1175/MWR-D-15-0260.1, doi:10.1175/MWR-D-15-0260.1.\u00a0\u21a9</p> </li> </ol>"},{"location":"reference/","title":"API reference","text":"<p>This page provides a summary of scoringrules' API. All functions are available in the top-level namespace of the package and are here organized by category.</p> <pre><code>.. currentmodule:: scoringrules\n\nEnsemble forecasts\n==================\n\nUnivariate\n------------------\n\n.. autosummary::\n    :toctree: generated\n\n    crps_ensemble\n    twcrps_ensemble\n    owcrps_ensemble\n    vrcrps_ensemble\n    gksuv_ensemble\n    twgksuv_ensemble\n    owgksuv_ensemble\n    vrgksuv_ensemble\n    clogs_ensemble\n    error_spread_score\n\n.. Multivariate\n.. --------------------\n\n.. .. autosummary::\n..     :toctree: generated\n\n..     energy_score\n..     twenergy_score\n..     owenergy_score\n..     vrenergy_score\n..     variogram_score\n..     owvariogram_score\n..     twvariogram_score\n..     vrvariogram_score\n..     gksmv_ensemble\n..     twgksmv_ensemble\n..     owgksmv_ensemble\n..     vrgksmv_ensemble\n\n.. Parametric distributions forecasts\n.. ====================================\n.. .. autosummary::\n..     :toctree: generated\n\n..     crps_beta\n..     crps_binomial\n..     crps_exponential\n..     crps_exponentialM\n..     crps_2pexponential\n..     crps_gamma\n..     crps_gev\n..     crps_gpd\n..     crps_gtclogistic\n..     crps_tlogistic\n..     crps_clogistic\n..     crps_gtcnormal\n..     crps_tnormal\n..     crps_cnormal\n..     crps_gtct\n..     crps_tt\n..     crps_ct\n..     crps_hypergeometric\n..     crps_laplace\n..     crps_logistic\n..     crps_loglaplace\n..     crps_loglogistic\n..     crps_lognormal\n..     crps_mixnorm\n..     crps_negbinom\n..     crps_normal\n..     crps_2pnormal\n..     crps_poisson\n..     crps_quantile\n..     crps_t\n..     crps_uniform\n..     logs_beta\n..     logs_binomial\n..     logs_ensemble\n..     logs_exponential\n..     logs_exponential2\n..     logs_2pexponential\n..     logs_gamma\n..     logs_gev\n..     logs_gpd\n..     logs_hypergeometric\n..     logs_laplace\n..     logs_loglaplace\n..     logs_logistic\n..     logs_loglogistic\n..     logs_lognormal\n..     logs_mixnorm\n..     logs_negbinom\n..     logs_normal\n..     logs_2pnormal\n..     logs_poisson\n..     logs_t\n..     logs_tlogistic\n..     logs_tnormal\n..     logs_tt\n..     logs_uniform\n\n.. Functions of distributions\n.. ==========================\n.. .. autosummary::\n..     :toctree: generated\n\n..     interval_score\n..     weighted_interval_score\n\n\n.. Categorical forecasts\n.. =================================\n.. .. autosummary::\n..     :toctree: generated\n\n..     brier_score\n..     rps_score\n..     log_score\n..     rls_score\n\n\n.. Backends\n.. ========\n.. .. autosummary::\n..     :toctree: generated\n\n..     register_backend\n</code></pre>"},{"location":"user_guide/","title":"User guide","text":""},{"location":"user_guide/#first-steps","title":"First steps","text":"<p>Start by importing the library in your code with <pre><code>import scoringrules as sr\n</code></pre></p> <p>the library API is simple: all metrics are available under the main namespace. Let's look at some examples:</p> <pre><code>import numpy as np\n\n# on scalars\nsr.brier_score(0.1, 1)\nsr.crps_normal(0.1, 1.2, 0.3)\n\n# on arrays\nsr.brier_score(np.random.uniform(0, 1, 100), np.random.binomial(1, 0.5, 100))\nsr.crps_lognormal(np.random.lognormal(0, 1, 100), np.random.randn(100), np.random.uniform(0.5, 1.5, 100))\n\n# ensemble metrics\nobs = np.random.randn(100)\nfct = obs[:,None] + np.random.randn(100, 21) * 0.1\n\nsr.crps_ensemble(obs, fct)\nsr.error_spread_score(obs, fct)\n\n# multivariate ensemble metrics\nobs = np.random.randn(100,3)\nfct = obs[:,None] + np.random.randn(100, 21, 3) * 0.1\n\nsr.energy_score(obs, fct)\nsr.variogram_score(obs, fct)\n</code></pre> <p>For the univariate ensemble metrics, the ensemble dimension is on the last axis unless you specify otherwise with the <code>axis</code> argument. For the multivariate ensemble metrics, the ensemble dimension and the variable dimension are on the second last and last axis respectively, unless specified otherwise with <code>m_axis</code> and <code>v_axis</code>.</p>"},{"location":"user_guide/#backends","title":"Backends","text":"<p>Scoringrules supports multiple backends. By default, the <code>numpy</code> and <code>numba</code> backends will be registered when importing the library. You can see the list of registered backends with</p> <pre><code>print(sr.backends)\n# {'numpy': &lt;scoringrules.backend.numpy.NumpyBackend at 0x2ba2d6f391b0&gt;,\n# 'numba': &lt;scoringrules.backend.numpy.NumbaBackend at 0x2ba2d6f38ac0&gt;}\n</code></pre> <p>and the currently active backend, used by default in all metrics, can be seen with</p> <pre><code>print(sr.backends.active)\n# &lt;scoringrules.backend.numpy.NumpyBackend at 0x2ba2d6f38ac0&gt;\n</code></pre> <p>The default backend can also be changed with</p> <p><pre><code>sr.backends.set_active(\"numba\")\nprint(sr.backends.active)\n# &lt;scoringrules.backend.numpy.NumbaBackend at 0x2ba2d6f38ac0&gt;\n</code></pre> When computing a metric, the <code>backend</code> argument can be used to override the default choice.</p> <p>To register a new backend, for example <code>torch</code>, simply use</p> <pre><code>sr.register_backend(\"torch\")\n</code></pre> <p>You can now use <code>torch</code> to compute metrics, either by setting it as the default backend or by specifying it on a specific metric:</p> <pre><code>sr.crps_normal(0.1, 1.0, 0.0, backend=\"torch\")\n</code></pre>"},{"location":"_build/_sources/","title":"scoringrules: probabilistic forecast verification metrics","text":"<pre><code>:maxdepth: 2\n:caption: Library:\n:hidden:\n\nuser_guide\ncontributing\nreference\n</code></pre> <pre><code>:maxdepth: 2\n:caption: Background:\n:hidden:\n\nscoring_rules\ncrps_estimators\n</code></pre>"},{"location":"_build/_sources/contributing/","title":"Contributing","text":"<p>We welcome contributions! You can help improve the library in many ways:</p> <ul> <li>Report issues or propose enhancements using on the GitHub issue tracker</li> <li>Improve or extend the codebase</li> <li>Improve or extend the documentation</li> </ul>"},{"location":"_build/_sources/contributing/#getting-started","title":"Getting started","text":"<p>Fork the repository on GitHub and clone it to your computer:</p> <pre><code>git clone https://github.com/&lt;your-username&gt;/scoringrules.git\n</code></pre> <p>We use uv for project management and packaging. Install it with</p> <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> <p>Then, you can install the library and all dependencies (including development dependencies) and install the pre-commit hooks:</p> <pre><code>uv install &amp;&amp; uv run pre-commit install\n</code></pre> <p>From here you can work on your changes! Once you're satisfied with your changes, and followed the additional instructions below, push everything to your repository and open a pull request on GitHub.</p>"},{"location":"_build/_sources/contributing/#contributing-to-the-codebase","title":"Contributing to the codebase","text":"<p>Don't forget to include new tests if necessary, then make sure that all tests are passing with</p> <pre><code>uv run pytest tests/\n</code></pre>"},{"location":"_build/_sources/contributing/#contributing-to-the-documentation","title":"Contributing to the documentation","text":"<p>You can work on the documentation by modifying <code>mkdocs.yaml</code> and files in <code>docs/</code>. The most convenient way to do it is to run</p> <pre><code>uvx --with-requirements docs/requirements.txt mkdocs serve\n</code></pre> <p>and open the locally hosted documentation on your browser. It will be updated automatically every time you make changes and save. If you edit or add pieces of LaTex math, please make sure they are rendered correctly.</p>"},{"location":"_build/_sources/crps_estimators/","title":"Crps estimators","text":"<p>(crps-estimators)=</p>"},{"location":"_build/_sources/crps_estimators/#crps-estimators","title":"CRPS estimators","text":""},{"location":"_build/_sources/crps_estimators/#integral-form-int","title":"Integral form (INT)","text":"<p>The numerical approximation of the cumulative integral over the finite ensemble.</p> <pre><code>:label: int\n\\text{CRPS}_{\\text{INT}}(M, y) = \\int_{\\mathbb{R}} \\left[ \\frac{1}{M}\n    \\sum_{i=1}^M \\mathbb{1}\\{x_i \\le x \\} - \\mathbb{1}\\{y \\le x\\}  \\right] ^2 dx\n</code></pre> <p>Runs with {math}<code>O(m\\cdot\\mathrm{log}m)</code> complexity, including the sorting of the ensemble.</p>"},{"location":"_build/_sources/crps_estimators/#energy-form-nrg","title":"Energy form (NRG)","text":"<p>Introduced by Gneiting and Raftery (2007):</p> <p>.. $$ \\text{CRPS}{\\text{NRG}}(M, y) = \\frac{1}{M} \\sum{i=1}^{M}|x_i - y| - \\frac{1}{2 M^2}\\sum_{i,j=1}^{M}|x_i - x_j|$$</p> <p>..  It is called the \"energy form\" because it is the one-dimensional case of the Energy Score.</p> <p>.. Runs with \\(O(m^2)\\) complexity.</p> <p>.. # Quantile decomposition form (QD)</p> <p>.. Introduced by Jordan (2016)<sup>1</sup>:</p> <p>.. \\(\\(\\mathrm{CRPS}_{\\mathrm{QD}}(M, y) = \\frac{2}{M^2} \\sum_{i=1}^{M}(x_i - y)\\left[M\\mathbb{1}\\{y \\le x_i\\} - i + \\frac{1}{2} \\right]\\)\\)</p> <p>.. Runs with \\(O(m\\cdot\\mathrm{log}m)\\) complexity, including the sorting of the ensemble.</p> <p>.. # Probability weighted moment form (PWM)</p> <p>.. Introduced by Taillardat et al. (2016)<sup>2</sup>:</p> <p>.. \\(\\(\\mathrm{CRPS}_{\\mathrm{NRG}}(M, y) = \\frac{1}{M} \\sum_{i=1}^{M}|x_i - y| + \\hat{\\beta_0} - 2\\hat{\\beta_1},\\)\\)</p> <p>.. where \\(\\hat{\\beta_0} = \\frac{1}{M} \\sum_{i=1}^{M}x_i\\) and \\(\\hat{\\beta_1} = \\frac{1}{M(M-1)} \\sum_{i=1}^{M}(i - 1)x_i\\). Runs with \\(O(m\\cdot\\mathrm{log}m)\\) complexity, including the sorting of the ensemble. --&gt;</p> <p>.. _Gneiting and Raftery: Gneiting, T., &amp; Raftery, A. E. (2007).      Strictly proper scoring rules, prediction, and estimation.     Journal of the American statistical Association, 102(477), 359-378.</p> <ol> <li> <p>Alexander Jordan. Facets of forecast evaluation. PhD thesis, Karlsruher Institut f\u00fcr Technologie (KIT), 2016. doi:10.5445/IR/1000063629.\u00a0\u21a9</p> </li> <li> <p>Maxime Taillardat, Olivier Mestre, Micha\u00ebl Zamo, and Philippe Naveau. Calibrated Ensemble Forecasts Using Quantile Regression Forests and Ensemble Model Output Statistics. Monthly Weather Review, 2016. URL: http://journals.ametsoc.org/doi/10.1175/MWR-D-15-0260.1, doi:10.1175/MWR-D-15-0260.1.\u00a0\u21a9</p> </li> </ol>"},{"location":"_build/_sources/reference/","title":"API reference","text":"<p>This page provides a summary of scoringrules' API. All functions are available in the top-level namespace of the package and are here organized by category.</p> <pre><code>.. currentmodule:: scoringrules\n\nEnsemble forecasts\n==================\n\nUnivariate\n------------------\n\n.. autosummary::\n    :toctree: generated\n\n    crps_ensemble\n    twcrps_ensemble\n    owcrps_ensemble\n    vrcrps_ensemble\n    gksuv_ensemble\n    twgksuv_ensemble\n    owgksuv_ensemble\n    vrgksuv_ensemble\n    clogs_ensemble\n    error_spread_score\n\n.. Multivariate\n.. --------------------\n\n.. .. autosummary::\n..     :toctree: generated\n\n..     energy_score\n..     twenergy_score\n..     owenergy_score\n..     vrenergy_score\n..     variogram_score\n..     owvariogram_score\n..     twvariogram_score\n..     vrvariogram_score\n..     gksmv_ensemble\n..     twgksmv_ensemble\n..     owgksmv_ensemble\n..     vrgksmv_ensemble\n\n.. Parametric distributions forecasts\n.. ====================================\n.. .. autosummary::\n..     :toctree: generated\n\n..     crps_beta\n..     crps_binomial\n..     crps_exponential\n..     crps_exponentialM\n..     crps_2pexponential\n..     crps_gamma\n..     crps_gev\n..     crps_gpd\n..     crps_gtclogistic\n..     crps_tlogistic\n..     crps_clogistic\n..     crps_gtcnormal\n..     crps_tnormal\n..     crps_cnormal\n..     crps_gtct\n..     crps_tt\n..     crps_ct\n..     crps_hypergeometric\n..     crps_laplace\n..     crps_logistic\n..     crps_loglaplace\n..     crps_loglogistic\n..     crps_lognormal\n..     crps_mixnorm\n..     crps_negbinom\n..     crps_normal\n..     crps_2pnormal\n..     crps_poisson\n..     crps_quantile\n..     crps_t\n..     crps_uniform\n..     logs_beta\n..     logs_binomial\n..     logs_ensemble\n..     logs_exponential\n..     logs_exponential2\n..     logs_2pexponential\n..     logs_gamma\n..     logs_gev\n..     logs_gpd\n..     logs_hypergeometric\n..     logs_laplace\n..     logs_loglaplace\n..     logs_logistic\n..     logs_loglogistic\n..     logs_lognormal\n..     logs_mixnorm\n..     logs_negbinom\n..     logs_normal\n..     logs_2pnormal\n..     logs_poisson\n..     logs_t\n..     logs_tlogistic\n..     logs_tnormal\n..     logs_tt\n..     logs_uniform\n\n.. Functions of distributions\n.. ==========================\n.. .. autosummary::\n..     :toctree: generated\n\n..     interval_score\n..     weighted_interval_score\n\n\n.. Categorical forecasts\n.. =================================\n.. .. autosummary::\n..     :toctree: generated\n\n..     brier_score\n..     rps_score\n..     log_score\n..     rls_score\n\n\n.. Backends\n.. ========\n.. .. autosummary::\n..     :toctree: generated\n\n..     register_backend\n</code></pre>"},{"location":"_build/_sources/user_guide/","title":"User guide","text":""},{"location":"_build/_sources/user_guide/#first-steps","title":"First steps","text":"<p>Start by importing the library in your code with <pre><code>import scoringrules as sr\n</code></pre></p> <p>the library API is simple: all metrics are available under the main namespace. Let's look at some examples:</p> <pre><code>import numpy as np\n\n# on scalars\nsr.brier_score(0.1, 1)\nsr.crps_normal(0.1, 1.2, 0.3)\n\n# on arrays\nsr.brier_score(np.random.uniform(0, 1, 100), np.random.binomial(1, 0.5, 100))\nsr.crps_lognormal(np.random.lognormal(0, 1, 100), np.random.randn(100), np.random.uniform(0.5, 1.5, 100))\n\n# ensemble metrics\nobs = np.random.randn(100)\nfct = obs[:,None] + np.random.randn(100, 21) * 0.1\n\nsr.crps_ensemble(obs, fct)\nsr.error_spread_score(obs, fct)\n\n# multivariate ensemble metrics\nobs = np.random.randn(100,3)\nfct = obs[:,None] + np.random.randn(100, 21, 3) * 0.1\n\nsr.energy_score(obs, fct)\nsr.variogram_score(obs, fct)\n</code></pre> <p>For the univariate ensemble metrics, the ensemble dimension is on the last axis unless you specify otherwise with the <code>axis</code> argument. For the multivariate ensemble metrics, the ensemble dimension and the variable dimension are on the second last and last axis respectively, unless specified otherwise with <code>m_axis</code> and <code>v_axis</code>.</p>"},{"location":"_build/_sources/user_guide/#backends","title":"Backends","text":"<p>Scoringrules supports multiple backends. By default, the <code>numpy</code> and <code>numba</code> backends will be registered when importing the library. You can see the list of registered backends with</p> <pre><code>print(sr.backends)\n# {'numpy': &lt;scoringrules.backend.numpy.NumpyBackend at 0x2ba2d6f391b0&gt;,\n# 'numba': &lt;scoringrules.backend.numpy.NumbaBackend at 0x2ba2d6f38ac0&gt;}\n</code></pre> <p>and the currently active backend, used by default in all metrics, can be seen with</p> <pre><code>print(sr.backends.active)\n# &lt;scoringrules.backend.numpy.NumpyBackend at 0x2ba2d6f38ac0&gt;\n</code></pre> <p>The default backend can also be changed with</p> <p><pre><code>sr.backends.set_active(\"numba\")\nprint(sr.backends.active)\n# &lt;scoringrules.backend.numpy.NumbaBackend at 0x2ba2d6f38ac0&gt;\n</code></pre> When computing a metric, the <code>backend</code> argument can be used to override the default choice.</p> <p>To register a new backend, for example <code>torch</code>, simply use</p> <pre><code>sr.register_backend(\"torch\")\n</code></pre> <p>You can now use <code>torch</code> to compute metrics, either by setting it as the default backend or by specifying it on a specific metric:</p> <pre><code>sr.crps_normal(0.1, 1.0, 0.0, backend=\"torch\")\n</code></pre>"},{"location":"api/brier/","title":"Brier Score","text":""},{"location":"api/brier/#scoringrules.brier_score","title":"scoringrules.brier_score","text":"<pre><code>brier_score(\n    observations: ArrayLike,\n    forecasts: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Brier Score (BS).</p> <p>The BS is formulated as</p> \\[ BS(f, y) = (f - y)^2, \\] <p>where \\(f \\in [0, 1]\\) is the predicted probability of an event and \\(y \\in \\{0, 1\\}\\) the actual outcome.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>Observed outcome, either 0 or 1.</p> required <code>forecasts</code> <code>NDArray</code> <p>Forecasted probabilities between 0 and 1.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>brier_score</code> <code>NDArray</code> <p>The computed Brier Score.</p>"},{"location":"api/brier/#scoringrules.rps_score","title":"scoringrules.rps_score","text":"<pre><code>rps_score(\n    observations: ArrayLike,\n    forecasts: ArrayLike,\n    /,\n    axis: int = -1,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the (Discrete) Ranked Probability Score (RPS).</p> <p>Suppose the outcome corresponds to one of \\(K\\) ordered categories. The RPS is defined as</p> \\[ RPS(f, y) = \\sum_{k=1}^{K}(\\tilde{f}_{k} - \\tilde{y}_{k})^2, \\] <p>where \\(f \\in [0, 1]^{K}\\) is a vector of length \\(K\\) containing forecast probabilities that each of the \\(K\\) categories will occur, and \\(y \\in \\{0, 1\\}^{K}\\) is a vector of length \\(K\\), with the \\(k\\)-th element equal to one if the \\(k\\)-th category occurs. We have \\(\\sum_{k=1}^{K} y_{k} = \\sum_{k=1}^{K} f_{k} = 1\\), and, for \\(k = 1, \\dots, K\\), \\(\\tilde{y}_{k} = \\sum_{i=1}^{k} y_{i}\\) and \\(\\tilde{f}_{k} = \\sum_{i=1}^{k} f_{i}\\).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>Array of 0's and 1's corresponding to unobserved and observed categories</p> required <code>forecasts</code> <code>ArrayLike</code> <p>Array of forecast probabilities for each category.</p> required <code>axis</code> <code>int</code> <p>The axis corresponding to the categories. Default is the last axis.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>Array</code> <p>The computed Ranked Probability Score.</p>"},{"location":"api/brier/#scoringrules.log_score","title":"scoringrules.log_score","text":"<pre><code>log_score(\n    observations: ArrayLike,\n    forecasts: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Logarithmic Score (LS) for probability forecasts for binary outcomes.</p> <p>The LS is formulated as</p> \\[ LS(f, y) = -\\log|f + y - 1|, \\] <p>where \\(f \\in [0, 1]\\) is the predicted probability of an event and \\(y \\in \\{0, 1\\}\\) the actual outcome.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>Observed outcome, either 0 or 1.</p> required <code>forecasts</code> <code>NDArray</code> <p>Forecasted probabilities between 0 and 1.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>Array</code> <p>The computed Log Score.</p>"},{"location":"api/brier/#scoringrules.rls_score","title":"scoringrules.rls_score","text":"<pre><code>rls_score(\n    observations: ArrayLike,\n    forecasts: ArrayLike,\n    /,\n    axis: int = -1,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the (Discrete) Ranked Logarithmic Score (RLS).</p> <p>Suppose the outcome corresponds to one of \\(K\\) ordered categories. The RLS is defined as</p> \\[ RPS(f, y) = -\\sum_{k=1}^{K} \\log|\\tilde{f}_{k} + \\tilde{y}_{k} - 1|, \\] <p>where \\(f \\in [0, 1]^{K}\\) is a vector of length \\(K\\) containing forecast probabilities that each of the \\(K\\) categories will occur, and \\(y \\in \\{0, 1\\}^{K}\\) is a vector of length \\(K\\), with the \\(k\\)-th element equal to one if the \\(k\\)-th category occurs. We have \\(\\sum_{k=1}^{K} y_{k} = \\sum_{k=1}^{K} f_{k} = 1\\), and, for \\(k = 1, \\dots, K\\), \\(\\tilde{y}_{k} = \\sum_{i=1}^{k} y_{i}\\) and \\(\\tilde{f}_{k} = \\sum_{i=1}^{k} f_{i}\\).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>Observed outcome, either 0 or 1.</p> required <code>forecasts</code> <code>NDArray</code> <p>Forecasted probabilities between 0 and 1.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>Array</code> <p>The computed Ranked Logarithmic Score.</p>"},{"location":"api/crps/","title":"Continuous Ranked Probability Score","text":"<p>Formally, the CRPS is expressed as</p> \\[\\text{CRPS}(F, y) = \\int_{\\mathbb{R}}[F(x)-\\mathbb{1}\\{y \\le x\\}]^2 dx\\] <p>where \\(F(x) = P(X&lt;x)\\) is the forecast CDF and \\(\\mathbb{1}\\{x \\le y\\}\\) the empirical CDF of the scalar observation \\(y\\). \\(\\mathbb{1}\\) is the indicator function. The CRPS can also be viewed as the Brier score integrated over all real-valued thresholds.</p>"},{"location":"api/crps/#analytical-formulations","title":"Analytical formulations","text":""},{"location":"api/crps/#scoringrules.crps_beta","title":"scoringrules.crps_beta","text":"<pre><code>crps_beta(\n    observation: ArrayLike,\n    a: ArrayLike,\n    b: ArrayLike,\n    /,\n    lower: ArrayLike = 0.0,\n    upper: ArrayLike = 1.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the beta distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(F_{\\alpha, \\beta}, y) = (u - l)\\left\\{ \\frac{y - l}{u - l} \\left( 2F_{\\alpha, \\beta} \\left( \\frac{y - l}{u - l} \\right) - 1 \\right) + \\frac{\\alpha}{\\alpha + \\beta} \\left( 1 - 2F_{\\alpha + 1, \\beta} \\left( \\frac{y - l}{u - l} \\right) - \\frac{2B(2\\alpha, 2\\beta)}{\\alpha B(\\alpha, \\beta)^{2}} \\right) \\right\\} \\] <p>where \\(F_{\\alpha, \\beta}\\) is the beta distribution function with shape parameters \\(\\alpha, \\beta &gt; 0\\), and lower and upper bounds \\(l, u \\in \\R\\), \\(l &lt; u\\).</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>a</code> <code>ArrayLike</code> <p>First shape parameter of the forecast beta distribution.</p> required <code>b</code> <code>ArrayLike</code> <p>Second shape parameter of the forecast beta distribution.</p> required <code>lower</code> <code>ArrayLike</code> <p>Lower bound of the forecast beta distribution.</p> <code>0.0</code> <code>upper</code> <code>ArrayLike</code> <p>Upper bound of the forecast beta distribution.</p> <code>1.0</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between Beta(a, b) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_beta(0.3, 0.7, 1.1)\n0.0850102437\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_binomial","title":"scoringrules.crps_binomial","text":"<pre><code>crps_binomial(\n    observation: ArrayLike,\n    n: ArrayLike,\n    prob: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the binomial distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(F_{n, p}, y) = 2 \\sum_{x = 0}^{n} f_{n,p}(x) (1\\{y &lt; x\\} - F_{n,p}(x) + f_{n,p}(x)/2) (x - y), \\] <p>where \\(f_{n, p}\\) and \\(F_{n, p}\\) are the PDF and CDF of the binomial distribution with size parameter \\(n = 0, 1, 2, ...\\) and probability parameter \\(p \\in [0, 1]\\).</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values as an integer or array of integers.</p> required <code>n</code> <code>ArrayLike</code> <p>Size parameter of the forecast binomial distribution as an integer or array of integers.</p> required <code>prob</code> <code>ArrayLike</code> <p>Probability parameter of the forecast binomial distribution as a float or array of floats.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between Binomial(n, prob) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_binomial(4, 10, 0.5)\n0.5955715179443359\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_exponential","title":"scoringrules.crps_exponential","text":"<pre><code>crps_exponential(\n    observation: ArrayLike,\n    rate: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the exponential distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[\\mathrm{CRPS}(F_{\\lambda}, y) = |y| - \\frac{2F_{\\lambda}(y)}{\\lambda} + \\frac{1}{2 \\lambda},\\] <p>where \\(F_{\\lambda}\\) is exponential distribution function with rate parameter \\(\\lambda &gt; 0\\).</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>rate</code> <code>ArrayLike</code> <p>Rate parameter of the forecast exponential distribution.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between Exp(rate) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; sr.crps_exponential(0.8, 3.0)\n0.360478635526275\n&gt;&gt;&gt; sr.crps_exponential(np.array([0.8, 0.9]), np.array([3.0, 2.0]))\narray([0.36047864, 0.24071795])\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_exponentialM","title":"scoringrules.crps_exponentialM","text":"<pre><code>crps_exponentialM(\n    observation: ArrayLike,\n    /,\n    mass: ArrayLike = 0.0,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the standard exponential distribution with a point mass at the boundary.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(F_{M}, y) = |y| - 2 (1 - M) F(y) + \\frac{(1 - M)**2}{2}, \\] \\[ \\mathrm{CRPS}(F_{M, \\mu, \\sigma}, y) = \\sigma \\mathrm{CRPS} \\left( F_{M}, \\frac{y - \\mu}{\\sigma} \\right), \\] <p>where \\(F_{M, \\mu, \\sigma}\\) is standard exponential distribution function generalised using a location parameter \\(\\mu\\) and scale parameter \\(\\sigma &lt; 0\\) and a point mass \\(M \\in [0, 1]\\) at \\(\\mu\\), \\(F_{M} = F_{M, 0, 1}\\), and</p> \\[ F(y) = 1 - \\exp(-y) \\] <p>for \\(y \\geq 0\\), and 0 otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>mass</code> <code>ArrayLike</code> <p>Mass parameter of the forecast exponential distribution.</p> <code>0.0</code> <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast exponential distribution.</p> <code>0.0</code> <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast exponential distribution.</p> <code>1.0</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between obs and ExpM(mass, location, scale).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_exponentialM(0.4, 0.2, 0.0, 1.0)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_2pexponential","title":"scoringrules.crps_2pexponential","text":"<pre><code>crps_2pexponential(\n    observation: ArrayLike,\n    scale1: ArrayLike,\n    scale2: ArrayLike,\n    location: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the two-piece exponential distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[\\mathrm{CRPS}(F_{\\sigma_{1}, \\sigma_{2}, \\mu}, y) = |y - \\mu| + \\frac{2\\sigma_{\\pm}^{2}}{\\sigma_{1} + \\sigma_{2}} \\exp \\left( - \\frac{|y - \\mu|}{\\sigma_{\\pm}} \\right) - \\frac{2\\sigma_{\\pm}^{2}}{\\sigma_{1} + \\sigma_{2}} + \\frac{\\sigma_{1}^{3} + \\sigma_{2}^{3}}{2(\\sigma_{1} + \\sigma_{2})^2} \\] <p>where \\(F_{\\sigma_{1}, \\sigma_{2}, \\mu}\\) is the two-piece exponential distribution function with scale parameters \\(\\sigma_{1}, \\sigma_{2} &gt; 0\\) and location parameter \\(\\mu\\). The parameter \\(\\sigma_{\\pm}\\) is equal to \\(\\sigma_{1}\\) if \\(y &lt; 0\\) and \\(\\sigma_{2}\\) if \\(y \\geq 0\\).</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>scale1</code> <code>ArrayLike</code> <p>First scale parameter of the forecast two-piece exponential distribution.</p> required <code>scale2</code> <code>ArrayLike</code> <p>Second scale parameter of the forecast two-piece exponential distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast two-piece exponential distribution.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between 2pExp(sigma1, sigma2, location) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_2pexponential(0.8, 3.0, 1.4, 0.0)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_gamma","title":"scoringrules.crps_gamma","text":"<pre><code>crps_gamma(\n    observation: ArrayLike,\n    shape: ArrayLike,\n    /,\n    rate: ArrayLike | None = None,\n    *,\n    scale: ArrayLike | None = None,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the gamma distribution.</p> <p>It is based on the following formulation from Scheuerer and M\u00f6ller (2015):</p> \\[ \\mathrm{CRPS}(F_{\\alpha, \\beta}, y) = y(2F_{\\alpha, \\beta}(y) - 1) - \\frac{\\alpha}{\\beta} (2 F_{\\alpha + 1, \\beta}(y) - 1) - \\frac{1}{\\beta B(1/2, \\alpha)}. \\] <p>where \\(F_{\\alpha, \\beta}\\) is gamma distribution function with shape parameter \\(\\alpha &gt; 0\\) and rate parameter \\(\\beta &gt; 0\\) (equivalently, with scale parameter \\(1/\\beta\\)).</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>shape</code> <code>ArrayLike</code> <p>Shape parameter of the forecast gamma distribution.</p> required <code>rate</code> <code>ArrayLike | None</code> <p>Rate parameter of the forecast rate distribution.</p> <code>None</code> <code>scale</code> <code>ArrayLike | None</code> <p>Scale parameter of the forecast scale distribution, where <code>scale = 1 / rate</code>.</p> <code>None</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between obs and Gamma(shape, rate).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_gamma(0.2, 1.1, 0.1)\n5.503536008961291\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both <code>rate</code> and <code>scale</code> are provided, or if neither is provided.</p>"},{"location":"api/crps/#scoringrules.crps_gev","title":"scoringrules.crps_gev","text":"<pre><code>crps_gev(\n    observation: ArrayLike,\n    shape: ArrayLike,\n    /,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the generalised extreme value (GEV) distribution.</p> <p>It is based on the following formulation from Friederichs and Thorarinsdottir (2012):</p> \\[ \\text{CRPS}(F_{\\xi, \\mu, \\sigma}, y) = \\sigma \\cdot \\text{CRPS}(F_{\\xi}, \\frac{y - \\mu}{\\sigma}) \\] <p>Special cases are handled as follows:</p> <ul> <li>For \\(\\xi = 0\\):</li> </ul> \\[ \\text{CRPS}(F_{\\xi}, y) = -y - 2\\text{Ei}(\\log F_{\\xi}(y)) + C - \\log 2 \\] <ul> <li>For \\(\\xi \\neq 0\\):</li> </ul> \\[ \\text{CRPS}(F_{\\xi}, y) = y(2F_{\\xi}(y) - 1) - 2G_{\\xi}(y) - \\frac{1 - (2 - 2^{\\xi}) \\Gamma(1 - \\xi)}{\\xi} \\] <p>where \\(C\\) is the Euler-Mascheroni constant, \\(\\text{Ei}\\) is the exponential integral, and \\(\\Gamma\\) is the gamma function. The GEV cumulative distribution function \\(F_{\\xi}\\) and the auxiliary function \\(G_{\\xi}\\) are defined as:</p> <ul> <li>For \\(\\xi = 0\\):</li> </ul> \\[ F_{\\xi}(x) = \\exp(-\\exp(-x)) \\] <ul> <li>For \\(\\xi \\neq 0\\):</li> </ul> \\[ F_{\\xi}(x) = \\begin{cases} 0, &amp; x \\leq \\frac{1}{\\xi} \\\\ \\exp(-(1 + \\xi x)^{-1/\\xi}), &amp; x &gt; \\frac{1}{\\xi} \\end{cases} \\] \\[ G_{\\xi}(x) = \\begin{cases} 0, &amp; x \\leq \\frac{1}{\\xi} \\\\ \\frac{F_{\\xi}(x)}{\\xi} + \\frac{\\Gamma_u(1-\\xi, -\\log F_{\\xi}(x))}{\\xi}, &amp; x &gt; \\frac{1}{\\xi} \\end{cases} \\] <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>shape</code> <code>ArrayLike</code> <p>Shape parameter of the forecast GEV distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast GEV distribution.</p> <code>0.0</code> <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast GEV distribution.</p> <code>1.0</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between obs and GEV(shape, location, scale).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_gev(0.3, 0.1)\n0.2924712413052034\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_gpd","title":"scoringrules.crps_gpd","text":"<pre><code>crps_gpd(\n    observation: ArrayLike,\n    shape: ArrayLike,\n    /,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    mass: ArrayLike = 0.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the generalised pareto distribution (GPD).</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(F_{M, \\xi}, y) = |y| - \\frac{2 (1 - M)}{1 - \\xi} \\left( 1 - (1 - F_{\\xi}(y))^{1 - \\xi} \\right) + \\frac{(1 - M)^{2}}{2 - \\xi}, \\] \\[ \\mathrm{CRPS}(F_{M, \\xi, \\mu, \\sigma}, y) = \\sigma \\mathrm{CRPS} \\left( F_{M, \\xi}, \\frac{y - \\mu}{\\sigma} \\right), \\] <p>where \\(F_{M, \\xi, \\mu, \\sigma}\\) is the GPD distribution function with shape parameter \\(\\xi &lt; 1\\), location parameter \\(\\mu\\), scale parameter \\(\\sigma &gt; 0\\), and point mass \\(M \\in [0, 1]\\) at the lower boundary. \\(F_{M, \\xi} = F_{M, \\xi, 0, 1}\\).</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>shape</code> <code>ArrayLike</code> <p>Shape parameter of the forecast GPD distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast GPD distribution.</p> <code>0.0</code> <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast GPD distribution.</p> <code>1.0</code> <code>mass</code> <code>ArrayLike</code> <p>Mass parameter at the lower boundary of the forecast GPD distribution.</p> <code>0.0</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between obs and GPD(shape, location, scale, mass).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_gpd(0.3, 0.9)\n0.6849331901197213\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_gtclogistic","title":"scoringrules.crps_gtclogistic","text":"<pre><code>crps_gtclogistic(\n    observation: ArrayLike,\n    location: ArrayLike,\n    scale: ArrayLike,\n    /,\n    lower: ArrayLike = float(\"-inf\"),\n    upper: ArrayLike = float(\"inf\"),\n    lmass: ArrayLike = 0.0,\n    umass: ArrayLike = 0.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the generalised truncated and censored logistic distribution.</p> \\[ \\mathrm{CRPS}(F_{l, L}^{u, U}, y) = |y - z| + uU^{2} - lL^{2} - \\left( \\frac{1 - L - U}{F(u) - F(l)} \\right) z \\left( \\frac{(1 - 2L) F(u) + (1 - 2U) F(l)}{1 - L - U} \\right) - \\left( \\frac{1 - L - U}{F(u) - F(l)} \\right) \\left( 2 \\log F(-z) - 2G(u)U - 2 G(l)L \\right) - \\left( \\frac{1 - L - U}{F(u) - F(l)} \\right)^{2} \\left( H(u) - H(l) \\right), \\] \\[ \\mathrm{CRPS}(F_{l, L, \\mu, \\sigma}^{u, U}, y) = \\sigma \\mathrm{CRPS}(F_{(l - \\mu)/\\sigma, L}^{(u - \\mu)/\\sigma, U}, \\frac{y - \\mu}{\\sigma}), \\] \\[G(x) = xF(x) + \\log F(-x),\\] \\[H(x) = F(x) - xF(x)^{2} + (1 - 2F(x))\\log F(-x),\\] <p>where \\(F\\) is the CDF of the standard logistic distribution, \\(F_{l, L, \\mu, \\sigma}^{u, U}\\) is the CDF of the logistic distribution truncated below at \\(l\\) and above at \\(u\\), with point masses \\(L, U &gt; 0\\) at the lower and upper boundaries, respectively, and location and scale parameters \\(\\mu\\) and \\(\\sigma &gt; 0\\).</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast distribution.</p> required <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast distribution.</p> required <code>lower</code> <code>ArrayLike</code> <p>Lower boundary of the truncated forecast distribution.</p> <code>float('-inf')</code> <code>upper</code> <code>ArrayLike</code> <p>Upper boundary of the truncated forecast distribution.</p> <code>float('inf')</code> <code>lmass</code> <code>ArrayLike</code> <p>Point mass assigned to the lower boundary of the forecast distribution.</p> <code>0.0</code> <code>umass</code> <code>ArrayLike</code> <p>Point mass assigned to the upper boundary of the forecast distribution.</p> <code>0.0</code> <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between gtcLogistic(location, scale, lower, upper, lmass, umass) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_gtclogistic(0.0, 0.1, 0.4, -1.0, 1.0, 0.1, 0.1)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_tlogistic","title":"scoringrules.crps_tlogistic","text":"<pre><code>crps_tlogistic(\n    observation: ArrayLike,\n    location: ArrayLike,\n    scale: ArrayLike,\n    /,\n    lower: ArrayLike = float(\"-inf\"),\n    upper: ArrayLike = float(\"inf\"),\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the truncated logistic distribution.</p> <p>It is based on the formulation for the generalised truncated and censored logistic distribution with lmass and umass set to zero.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast distribution.</p> required <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast distribution.</p> required <code>lower</code> <code>ArrayLike</code> <p>Lower boundary of the truncated forecast distribution.</p> <code>float('-inf')</code> <code>upper</code> <code>ArrayLike</code> <p>Upper boundary of the truncated forecast distribution.</p> <code>float('inf')</code> <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between tLogistic(location, scale, lower, upper) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_tlogistic(0.0, 0.1, 0.4, -1.0, 1.0)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_clogistic","title":"scoringrules.crps_clogistic","text":"<pre><code>crps_clogistic(\n    observation: ArrayLike,\n    location: ArrayLike,\n    scale: ArrayLike,\n    /,\n    lower: ArrayLike = float(\"-inf\"),\n    upper: ArrayLike = float(\"inf\"),\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the censored logistic distribution.</p> <p>It is based on the formulation for the generalised truncated and censored logistic distribution with lmass and umass set to the tail probabilities of the predictive distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast distribution.</p> required <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast distribution.</p> required <code>lower</code> <code>ArrayLike</code> <p>Lower boundary of the truncated forecast distribution.</p> <code>float('-inf')</code> <code>upper</code> <code>ArrayLike</code> <p>Upper boundary of the truncated forecast distribution.</p> <code>float('inf')</code> <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between cLogistic(location, scale, lower, upper) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_clogistic(0.0, 0.1, 0.4, -1.0, 1.0)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_gtcnormal","title":"scoringrules.crps_gtcnormal","text":"<pre><code>crps_gtcnormal(\n    observation: ArrayLike,\n    location: ArrayLike,\n    scale: ArrayLike,\n    /,\n    lower: ArrayLike = float(\"-inf\"),\n    upper: ArrayLike = float(\"inf\"),\n    lmass: ArrayLike = 0.0,\n    umass: ArrayLike = 0.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the generalised truncated and censored normal distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(F_{l, L}^{u, U}, y) = |y - z| + uU^{2} - lL^{2} + \\left( \\frac{1 - L - U}{\\Phi(u) - \\Phi(l)} \\right) z \\left( 2 \\Phi(z) - \\frac{(1 - 2L) \\Phi(u) + (1 - 2U) \\Phi(l)}{1 - L - U} \\right) + \\left( \\frac{1 - L - U}{\\Phi(u) - \\Phi(l)} \\right) \\left( 2 \\phi(z) - 2 \\phi(u)U - 2 \\phi(l)L \\right) - \\left( \\frac{1 - L - U}{\\Phi(u) - \\Phi(l)} \\right)^{2} \\left( \\frac{1}{\\sqrt{\\pi}} \\right) \\left( \\Phi(u \\sqrt{2}) - \\Phi(l \\sqrt{2}) \\right), \\] \\[ \\mathrm{CRPS}(F_{l, L, \\mu, \\sigma}^{u, U}, y) = \\sigma \\mathrm{CRPS}(F_{(l - \\mu)/\\sigma, L}^{(u - \\mu)/\\sigma, U}, \\frac{y - \\mu}{\\sigma}), \\] <p>where \\(\\Phi\\) and \\(\\phi\\) are respectively the CDF and PDF of the standard normal distribution, \\(F_{l, L, \\mu, \\sigma}^{u, U}\\) is the CDF of the normal distribution truncated below at \\(l\\) and above at \\(u\\), with point masses \\(L, U &gt; 0\\) at the lower and upper boundaries, respectively, and location and scale parameters \\(\\mu\\) and \\(\\sigma &gt; 0\\). \\(F_{l, L}^{u, U} = F_{l, L, 0, 1}^{u, U}\\).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoring rules as sr\n&gt;&gt;&gt; sr.crps_gtcnormal(0.0, 0.1, 0.4, -1.0, 1.0, 0.1, 0.1)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_tnormal","title":"scoringrules.crps_tnormal","text":"<pre><code>crps_tnormal(\n    observation: ArrayLike,\n    location: ArrayLike,\n    scale: ArrayLike,\n    /,\n    lower: ArrayLike = float(\"-inf\"),\n    upper: ArrayLike = float(\"inf\"),\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the truncated normal distribution.</p> <p>It is based on the formulation for the generalised truncated and censored normal distribution with distribution with lmass and umass set to zero.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast distribution.</p> required <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast distribution.</p> required <code>lower</code> <code>ArrayLike</code> <p>Lower boundary of the truncated forecast distribution.</p> <code>float('-inf')</code> <code>upper</code> <code>ArrayLike</code> <p>Upper boundary of the truncated forecast distribution.</p> <code>float('inf')</code> <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between tNormal(location, scale, lower, upper) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_tnormal(0.0, 0.1, 0.4, -1.0, 1.0)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_cnormal","title":"scoringrules.crps_cnormal","text":"<pre><code>crps_cnormal(\n    observation: ArrayLike,\n    location: ArrayLike,\n    scale: ArrayLike,\n    /,\n    lower: ArrayLike = float(\"-inf\"),\n    upper: ArrayLike = float(\"inf\"),\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the censored normal distribution.</p> <p>It is based on the formulation for the generalised truncated and censored normal distribution with lmass and umass set to the tail probabilities of the predictive distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast distribution.</p> required <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast distribution.</p> required <code>lower</code> <code>ArrayLike</code> <p>Lower boundary of the truncated forecast distribution.</p> <code>float('-inf')</code> <code>upper</code> <code>ArrayLike</code> <p>Upper boundary of the truncated forecast distribution.</p> <code>float('inf')</code> <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between cNormal(location, scale, lower, upper) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_cnormal(0.0, 0.1, 0.4, -1.0, 1.0)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_gtct","title":"scoringrules.crps_gtct","text":"<pre><code>crps_gtct(\n    observation: ArrayLike,\n    df: ArrayLike,\n    /,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    lower: ArrayLike = float(\"-inf\"),\n    upper: ArrayLike = float(\"inf\"),\n    lmass: ArrayLike = 0.0,\n    umass: ArrayLike = 0.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the generalised truncated and censored t distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(F_{l, L, \\nu}^{u, U}, y) = |y - z| + uU^{2} - lL^{2} + \\left( \\frac{1 - L - U}{F_{\\nu}(u) - F_{\\nu}(l)} \\right) z \\left( 2 F_{\\nu}(z) - \\frac{(1 - 2L) F_{\\nu}(u) + (1 - 2U) F_{\\nu}(l)}{1 - L - U} \\right) - \\left( \\frac{1 - L - U}{F_{\\nu}(u) - F_{\\nu}(l)} \\right) \\left( 2 G_{\\nu}(z) - 2 G_{\\nu}(u)U - 2 G_{\\nu}(l)L \\right) - \\left( \\frac{1 - L - U}{F_{\\nu}(u) - F_{\\nu}(l)} \\right)^{2} \\bar{B}_{\\nu} \\left( H_{\\nu}(u) - H_{\\nu}(l) \\right), \\] \\[ \\mathrm{CRPS}(F_{l, L, \\nu, \\mu, \\sigma}^{u, U}, y) = \\sigma \\mathrm{CRPS}(F_{(l - \\mu)/\\sigma, L, \\nu}^{(u - \\mu)/\\sigma, U}, \\frac{y - \\mu}{\\sigma}), \\] \\[ G_{\\nu}(x) = - \\left( \\frac{\\nu + x^{2}}{\\nu - 1} \\right) f_{\\nu}(x), \\] \\[ H_{\\nu}(x) = \\frac{1}{2} + \\frac{1}{2} \\mathrm{sgn}(x) I \\left( \\frac{1}{2}, \\nu - \\frac{1}{2}, \\frac{x^{2}}{\\nu + x^{2}} \\right), \\] \\[ \\bar{B}_{\\nu} = \\left( \\frac{2 \\sqrt{\\nu}}{\\nu - 1} \\right) \\frac{B(\\frac{1}{2}, \\nu - \\frac{1}{2})}{B(\\frac{1}{2}, \\frac{\\nu}{2})^{2}}, \\] <p>where \\(F_{\\nu}\\) is the CDF of the standard t distribution with \\(\\nu &gt; 1\\) degrees of freedom, distribution, \\(F_{l, L, \\nu, \\mu, \\sigma}^{u, U}\\) is the CDF of the t distribution truncated below at \\(l\\) and above at \\(u\\), with point masses \\(L, U &gt; 0\\) at the lower and upper boundaries, respectively, and degrees of freedom, location and scale parameters \\(\\nu &gt; 1\\), \\(\\mu\\) and \\(\\sigma &gt; 0\\). \\(F_{l, L, \\nu}^{u, U} = F_{l, L, \\nu, 0, 1}^{u, U}\\).</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>df</code> <code>ArrayLike</code> <p>Degrees of freedom parameter of the forecast distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast distribution.</p> <code>0.0</code> <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast distribution.</p> <code>1.0</code> <code>lower</code> <code>ArrayLike</code> <p>Lower boundary of the truncated forecast distribution.</p> <code>float('-inf')</code> <code>upper</code> <code>ArrayLike</code> <p>Upper boundary of the truncated forecast distribution.</p> <code>float('inf')</code> <code>lmass</code> <code>ArrayLike</code> <p>Point mass assigned to the lower boundary of the forecast distribution.</p> <code>0.0</code> <code>umass</code> <code>ArrayLike</code> <p>Point mass assigned to the upper boundary of the forecast distribution.</p> <code>0.0</code> <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between gtct(df, location, scale, lower, upper, lmass, umass) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_gtct(0.0, 2.0, 0.1, 0.4, -1.0, 1.0, 0.1, 0.1)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_tt","title":"scoringrules.crps_tt","text":"<pre><code>crps_tt(\n    observation: ArrayLike,\n    df: ArrayLike,\n    /,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    lower: ArrayLike = float(\"-inf\"),\n    upper: ArrayLike = float(\"inf\"),\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the truncated t distribution.</p> <p>It is based on the formulation for the generalised truncated and censored t distribution with lmass and umass set to zero.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>df</code> <code>ArrayLike</code> <p>Degrees of freedom parameter of the forecast distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast distribution.</p> <code>0.0</code> <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast distribution.</p> <code>1.0</code> <code>lower</code> <code>ArrayLike</code> <p>Lower boundary of the truncated forecast distribution.</p> <code>float('-inf')</code> <code>upper</code> <code>ArrayLike</code> <p>Upper boundary of the truncated forecast distribution.</p> <code>float('inf')</code> <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between tt(df, location, scale, lower, upper) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_tt(0.0, 2.0, 0.1, 0.4, -1.0, 1.0)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_ct","title":"scoringrules.crps_ct","text":"<pre><code>crps_ct(\n    observation: ArrayLike,\n    df: ArrayLike,\n    /,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    lower: ArrayLike = float(\"-inf\"),\n    upper: ArrayLike = float(\"inf\"),\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the censored t distribution.</p> <p>It is based on the formulation for the generalised truncated and censored t distribution with lmass and umass set to the tail probabilities of the predictive distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>df</code> <code>ArrayLike</code> <p>Degrees of freedom parameter of the forecast distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast distribution.</p> <code>0.0</code> <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast distribution.</p> <code>1.0</code> <code>lower</code> <code>ArrayLike</code> <p>Lower boundary of the truncated forecast distribution.</p> <code>float('-inf')</code> <code>upper</code> <code>ArrayLike</code> <p>Upper boundary of the truncated forecast distribution.</p> <code>float('inf')</code> <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between ct(df, location, scale, lower, upper) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_ct(0.0, 2.0, 0.1, 0.4, -1.0, 1.0)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_hypergeometric","title":"scoringrules.crps_hypergeometric","text":"<pre><code>crps_hypergeometric(\n    observation: ArrayLike,\n    m: ArrayLike,\n    n: ArrayLike,\n    k: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the hypergeometric distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(F_{m, n, k}, y) = 2 \\sum_{x = 0}^{n} f_{m,n,k}(x) (1\\{y &lt; x\\} - F_{m,n,k}(x) + f_{m,n,k}(x)/2) (x - y), \\] <p>where \\(f_{m, n, k}\\) and \\(F_{m, n, k}\\) are the PDF and CDF of the hypergeometric distribution with population parameters \\(m,n = 0, 1, 2, ...\\) and size parameter \\(k = 0, ..., m + n\\).</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>m</code> <code>ArrayLike</code> <p>Number of success states in the population.</p> required <code>n</code> <code>ArrayLike</code> <p>Number of failure states in the population.</p> required <code>k</code> <code>ArrayLike</code> <p>Number of draws, without replacement. Must be in 0, 1, ..., m + n.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between obs and Hypergeometric(m, n, k).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_hypergeometric(5, 7, 13, 12)\n0.44697415547610597\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_laplace","title":"scoringrules.crps_laplace","text":"<pre><code>crps_laplace(\n    observation: ArrayLike,\n    /,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the laplace distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(F, y) = |y - \\mu| + \\sigma \\exp ( -| y - \\mu| / \\sigma) - \\frac{3\\sigma}{4}, \\] <p>where \\(\\mu\\) and \\(\\sigma &gt; 0\\) are the location and scale parameters of the Laplace distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>Observed values.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast laplace distribution.</p> <code>0.0</code> <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast laplace distribution.</p> <code>1.0</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between obs and Laplace(location, scale).</p> <code>&gt;&gt;&gt; sr.crps_laplace(0.3, 0.1, 0.2)</code> <code>0.12357588823428847</code>"},{"location":"api/crps/#scoringrules.crps_logistic","title":"scoringrules.crps_logistic","text":"<pre><code>crps_logistic(\n    observation: ArrayLike,\n    mu: ArrayLike,\n    sigma: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the logistic distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(\\mathcal{L}(\\mu, \\sigma), y) = \\sigma \\left\\{ \\omega - 2 \\log F(\\omega) - 1 \\right\\}, \\] <p>where \\(F(\\omega)\\) is the CDF of the standard logistic distribution at the normalized prediction error \\(\\omega = \\frac{y - \\mu}{\\sigma}\\).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <p>Observed values.</p> required <code>mu</code> <code>ArrayLike</code> <p>Location parameter of the forecast logistic distribution.</p> required <code>sigma</code> <code>ArrayLike</code> <p>Scale parameter of the forecast logistic distribution.</p> required <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS for the Logistic(mu, sigma) forecasts given the observations.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_logistic(0.0, 0.4, 0.1)\n0.30363\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_loglaplace","title":"scoringrules.crps_loglaplace","text":"<pre><code>crps_loglaplace(\n    observation: ArrayLike,\n    locationlog: ArrayLike,\n    scalelog: ArrayLike,\n    *,\n    backend: Backend = None\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the log-Laplace distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(F_{\\mu, \\sigma}, y) = y (2 F_{\\mu, \\sigma}(y) - 1) + \\exp(\\mu) \\left( \\frac{\\sigma}{4 - \\sigma^{2}} + A(y) \\right), \\] <p>where \\(F_{\\mu, \\sigma}\\) is the CDF of the log-laplace distribution with location parameter \\(\\mu\\) and scale parameter \\(\\sigma \\in (0, 1)\\), and</p> \\[ A(y) = \\frac{1}{1 + \\sigma} \\left( 1 - (2 F_{\\mu, \\sigma}(y) - 1)^{1 + \\sigma} \\right), \\] <p>if \\(y &lt; \\exp{\\mu}\\), and</p> \\[ A(y) = \\frac{-1}{1 - \\sigma} \\left( 1 - (2 (1 - F_{\\mu, \\sigma}(y)))^{1 - \\sigma} \\right), \\] <p>if \\(y \\ge \\exp{\\mu}\\).</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>Observed values.</p> required <code>locationlog</code> <code>ArrayLike</code> <p>Location parameter of the forecast log-laplace distribution.</p> required <code>scalelog</code> <code>ArrayLike</code> <p>Scale parameter of the forecast log-laplace distribution.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between obs and Loglaplace(locationlog, scalelog).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_loglaplace(3.0, 0.1, 0.9)\n1.162020513653791\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_loglogistic","title":"scoringrules.crps_loglogistic","text":"<pre><code>crps_loglogistic(\n    observation: ArrayLike,\n    mulog: ArrayLike,\n    sigmalog: ArrayLike,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the log-logistic distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\text{CRPS}(y, F_{\\mu,\\sigma}) = y \\left( 2F_{\\mu,\\sigma}(y) - 1 \\right) - 2 \\exp(\\mu) I\\left(F_{\\mu,\\sigma}(y); 1 + \\sigma, 1 - \\sigma\\right) \\\\ + \\exp(\\mu)(1 - \\sigma) B(1 + \\sigma, 1 - \\sigma) \\] <p>where \\( F_{\\mu,\\sigma}(x) \\) is the cumulative distribution function (CDF) of the log-logistic distribution, defined as:</p> \\[ F_{\\mu,\\sigma}(x) = \\begin{cases} 0, &amp; x \\leq 0 \\\\ \\left( 1 + \\exp\\left(-\\frac{\\log x - \\mu}{\\sigma}\\right) \\right)^{-1}, &amp; x &gt; 0 \\end{cases} \\] <p>\\(B\\) is the beta function, and \\(I\\) is the regularised incomplete beta function.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>mulog</code> <code>ArrayLike</code> <p>Location parameter of the log-logistic distribution.</p> required <code>sigmalog</code> <code>ArrayLike</code> <p>Scale parameter of the log-logistic distribution.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between obs and Loglogis(mulog, sigmalog).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_loglogistic(3.0, 0.1, 0.9)\n1.1329527730161177\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_lognormal","title":"scoringrules.crps_lognormal","text":"<pre><code>crps_lognormal(\n    observation: ArrayLike,\n    mulog: ArrayLike,\n    sigmalog: ArrayLike,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the lognormal distribution.</p> <p>It is based on the formulation introduced by Baran and Lerch (2015)</p> \\[ \\mathrm{CRPS}(\\mathrm{log}\\mathcal{N}(\\mu, \\sigma), y) = y [2 \\Phi(y) - 1] - 2 \\mathrm{exp}(\\mu + \\frac{\\sigma^2}{2}) \\left[ \\Phi(\\omega - \\sigma) + \\Phi(\\frac{\\sigma}{\\sqrt{2}}) \\right]\\] <p>where \\(\\Phi\\) is the CDF of the standard normal distribution and \\(\\omega = \\frac{\\mathrm{log}y - \\mu}{\\sigma}\\).</p> <p>Note that mean and standard deviation are not the values for the distribution itself, but of the underlying normal distribution it is derived from.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>mulog</code> <code>ArrayLike</code> <p>Mean of the normal underlying distribution.</p> required <code>sigmalog</code> <code>ArrayLike</code> <p>Standard deviation of the underlying normal distribution.</p> required <p>Returns:</p> Name Type Description <code>crps</code> <code>ArrayLike</code> <p>The CRPS between Lognormal(mu, sigma) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_lognormal(0.1, 0.4, 0.0)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_mixnorm","title":"scoringrules.crps_mixnorm","text":"<pre><code>crps_mixnorm(\n    observation: ArrayLike,\n    m: ArrayLike,\n    s: ArrayLike,\n    /,\n    w: ArrayLike = None,\n    axis: ArrayLike = -1,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for a mixture of normal distributions.</p> <p>It is based on the following formulation from Grimit et al. (2006):</p> \\[ \\mathrm{CRPS}(F, y) = \\sum_{i=1}^{M} w_{i} A(y - \\mu_{i}, \\sigma_{i}^{2}) - \\frac{1}{2} \\sum_{i=1}^{M} \\sum_{j=1}^{M} w_{i} w_{j} A(\\mu_{i} - \\mu_{j}, \\sigma_{i}^{2} + \\sigma_{j}^{2}), \\] <p>where \\(F(x) = \\sum_{i=1}^{M} w_{i} \\Phi \\left( \\frac{x - \\mu_{i}}{\\sigma_{i}} \\right)\\), and \\(A(\\mu, \\sigma^{2}) = \\mu (2 \\Phi(\\frac{\\mu}{\\sigma}) - 1) + 2\\sigma \\phi(\\frac{\\mu}{\\sigma}).\\)</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>m</code> <code>ArrayLike</code> <p>Means of the component normal distributions.</p> required <code>s</code> <code>ArrayLike</code> <p>Standard deviations of the component normal distributions.</p> required <code>w</code> <code>ArrayLike</code> <p>Non-negative weights assigned to each component.</p> <code>None</code> <code>axis</code> <code>ArrayLike</code> <p>The axis corresponding to the mixture components. Default is the last axis.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The CRPS between MixNormal(m, s) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_mixnormal(0.0, [0.1, -0.3, 1.0], [0.4, 2.1, 0.7], [0.1, 0.2, 0.7])\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_negbinom","title":"scoringrules.crps_negbinom","text":"<pre><code>crps_negbinom(\n    observation: ArrayLike,\n    n: ArrayLike,\n    /,\n    prob: ArrayLike | None = None,\n    *,\n    mu: ArrayLike | None = None,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the negative binomial distribution.</p> <p>It is based on the following formulation from Wei and Held (2014):</p> \\[ \\mathrm{CRPS}(F_{n, p}, y) = y (2 F_{n, p}(y) - 1) - \\frac{n(1 - p)}{p^{2}} \\left( p (2 F_{n+1, p}(y - 1) - 1) + _{2} F_{1} \\left( n + 1, \\frac{1}{2}; 2; -\\frac{4(1 - p)}{p^{2}} \\right) \\right), \\] <p>where \\(F_{n, p}\\) is the CDF of the negative binomial distribution with size parameter \\(n &gt; 0\\) and probability parameter \\(p \\in (0, 1]\\). The mean of the negative binomial distribution is \\(\\mu = n (1 - p)/p\\).</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>n</code> <code>ArrayLike</code> <p>Size parameter of the forecast negative binomial distribution.</p> required <code>prob</code> <code>ArrayLike | None</code> <p>Probability parameter of the forecast negative binomial distribution.</p> <code>None</code> <code>mu</code> <code>ArrayLike | None</code> <p>Mean of the forecast negative binomial distribution.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between NegBinomial(n, prob) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_negbinom(2, 5, 0.5)\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both <code>prob</code> and <code>mu</code> are provided, or if neither is provided.</p>"},{"location":"api/crps/#scoringrules.crps_normal","title":"scoringrules.crps_normal","text":"<pre><code>crps_normal(\n    observation: ArrayLike,\n    mu: ArrayLike,\n    sigma: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the normal distribution.</p> <p>It is based on the following formulation from Geiting et al. (2005):</p> \\[ \\mathrm{CRPS}(\\mathcal{N}(\\mu, \\sigma), y) = \\sigma \\Bigl\\{ \\omega [\\Phi(\u03c9) - 1] + 2 \\phi(\\omega) - \\frac{1}{\\sqrt{\\pi}} \\Bigl\\},\\] <p>where \\(\\Phi(\u03c9)\\) and \\(\\phi(\u03c9)\\) are respectively the CDF and PDF of the standard normal distribution at the normalized prediction error \\(\\omega = \\frac{y - \\mu}{\\sigma}\\).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <p>The observed values.</p> required <code>mu</code> <code>ArrayLike</code> <p>Mean of the forecast normal distribution.</p> required <code>sigma</code> <code>ArrayLike</code> <p>Standard deviation of the forecast normal distribution.</p> required <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between Normal(mu, sigma) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_normal(0.0, 0.1, 0.4)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_2pnormal","title":"scoringrules.crps_2pnormal","text":"<pre><code>crps_2pnormal(\n    observation: ArrayLike,\n    scale1: ArrayLike,\n    scale2: ArrayLike,\n    location: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the two-piece normal distribution.</p> <p>It is based on the following relationship given in Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(F_{\\sigma_{1}, \\sigma_{2}, \\mu}, y) = \\sigma_{1} \\mathrm{CRPS} \\left( F_{-\\infty,0}^{0, \\sigma_{2}/(\\sigma_{1} + \\sigma_{2})}, \\frac{\\min(0, y - \\mu)}{\\sigma_{1}} \\right) + \\sigma_{2} \\mathrm{CRPS} \\left( F_{0, \\sigma_{1}/(\\sigma_{1} + \\sigma_{2})}^{\\infty, 0}, \\frac{\\min(0, y - \\mu)}{\\sigma_{2}} \\right), \\] <p>where \\(F_{\\sigma_{1}, \\sigma_{2}, \\mu}\\) is the two-piece normal distribution with scale1 and scale2 parameters \\(\\sigma_{1}, \\sigma_{2} &gt; 0\\) and location parameter \\(\\mu\\), and \\(F_{l, L}^{u, U}\\) is the CDF of the generalised truncated and censored normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <p>The observed values.</p> required <code>scale1</code> <code>ArrayLike</code> <p>Scale parameter of the lower half of the forecast two-piece normal distribution.</p> required <code>scale2</code> <code>ArrayLike</code> <p>Scale parameter of the upper half of the forecast two-piece normal distribution.</p> required <code>mu</code> <p>Location parameter of the forecast two-piece normal distribution.</p> required <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between 2pNormal(scale1, scale2, mu) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_2pnormal(0.0, 0.4, 2.0, 0.1)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_poisson","title":"scoringrules.crps_poisson","text":"<pre><code>crps_poisson(\n    observation: ArrayLike,\n    mean: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the Poisson distribution.</p> <p>It is based on the following formulation from Wei and Held (2014):</p> \\[ \\mathrm{CRPS}(F_{\\lambda}, y) = (y - \\lambda) (2F_{\\lambda}(y) - 1) + 2 \\lambda f_{\\lambda}(\\lfloor y \\rfloor ) - \\lambda \\exp (-2 \\lambda) (I_{0} (2 \\lambda) + I_{1} (2 \\lambda))..\\] <p>where \\(F_{\\lambda}\\) is Poisson distribution function with mean parameter \\(\\lambda &gt; 0\\), and \\(I_{0}\\) and \\(I_{1}\\) are modified Bessel functions of the first kind.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>mean</code> <code>ArrayLike</code> <p>Mean parameter of the forecast poisson distribution.</p> required <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between Pois(mean) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_poisson(1, 2)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_t","title":"scoringrules.crps_t","text":"<pre><code>crps_t(\n    observation: ArrayLike,\n    df: ArrayLike,\n    /,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the student's t distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(F, y) = \\sigma \\left\\{ \\omega (2 F_{\\nu} (\\omega) - 1) + 2 f_{\\nu} \\left( \\frac{\\nu + \\omega^{2}}{\\nu - 1} \\right) - \\frac{2 \\sqrt{\\nu}}{\\nu - 1} \\frac{B(\\frac{1}{2}, \\nu - \\frac{1}{2})}{B(\\frac{1}{2}, \\frac{\\nu}{2}^{2})}  \\right\\}, \\] <p>where \\(\\omega = (y - \\mu)/\\sigma\\), where \\(\\nu &gt; 1, \\mu\\), and \\(\\sigma &gt; 0\\) are the degrees of freedom, location, and scale parameters respectively of the Student's t distribution, and \\(f_{\\nu}\\) and \\(F_{\\nu}\\) are the PDF and CDF of the standard Student's t distribution with \\(\\nu\\) degrees of freedom.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>df</code> <code>ArrayLike</code> <p>Degrees of freedom parameter of the forecast t distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast t distribution.</p> <code>0.0</code> <code>sigma</code> <p>Scale parameter of the forecast t distribution.</p> required <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between t(df, location, scale) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_t(0.0, 0.1, 0.4, 0.1)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_uniform","title":"scoringrules.crps_uniform","text":"<pre><code>crps_uniform(\n    observation: ArrayLike,\n    min: ArrayLike,\n    max: ArrayLike,\n    /,\n    lmass: ArrayLike = 0.0,\n    umass: ArrayLike = 0.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the uniform distribution.</p> <p>It is based on the following formulation from Jordan et al. (2019):</p> \\[ \\mathrm{CRPS}(\\mathcal{U}_{L}^{U}(l, u), y) = (u - l) \\left\\{ | \\frac{y - l}{u - l} - F \\left( \\frac{y - l}{u - l} \\right) | + F \\left( \\frac{y - l}{u - l} \\right)^{2} (1 - L - U) - F \\left( \\frac{y - l}{u - l} \\right) (1 - 2L) + \\frac{(1 - L - U)^{2}}{3} + (1 - L)U \\right\\},\\] <p>where \\(\\mathcal{U}_{L}^{U}(l, u)\\) is the uniform distribution with lower bound \\(l\\), upper bound \\(u &gt; l\\), point mass \\(L\\) on the lower bound, and point mass \\(U\\) on the upper bound. We must have that \\(L, U \\ge 0, L + U &lt; 1\\).</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>min</code> <code>ArrayLike</code> <p>Lower bound of the forecast uniform distribution.</p> required <code>max</code> <code>ArrayLike</code> <p>Upper bound of the forecast uniform distribution.</p> required <code>lmass</code> <code>ArrayLike</code> <p>Point mass on the lower bound of the forecast uniform distribution.</p> <code>0.0</code> <code>umass</code> <code>ArrayLike</code> <p>Point mass on the upper bound of the forecast uniform distribution.</p> <code>0.0</code> <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between U(min, max, lmass, umass) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_uniform(0.4, 0.0, 1.0, 0.0, 0.0)\n</code></pre>"},{"location":"api/crps/#scoringrules.crps_normal","title":"scoringrules.crps_normal","text":"<pre><code>crps_normal(\n    observation: ArrayLike,\n    mu: ArrayLike,\n    sigma: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the closed form of the CRPS for the normal distribution.</p> <p>It is based on the following formulation from Geiting et al. (2005):</p> \\[ \\mathrm{CRPS}(\\mathcal{N}(\\mu, \\sigma), y) = \\sigma \\Bigl\\{ \\omega [\\Phi(\u03c9) - 1] + 2 \\phi(\\omega) - \\frac{1}{\\sqrt{\\pi}} \\Bigl\\},\\] <p>where \\(\\Phi(\u03c9)\\) and \\(\\phi(\u03c9)\\) are respectively the CDF and PDF of the standard normal distribution at the normalized prediction error \\(\\omega = \\frac{y - \\mu}{\\sigma}\\).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <p>The observed values.</p> required <code>mu</code> <code>ArrayLike</code> <p>Mean of the forecast normal distribution.</p> required <code>sigma</code> <code>ArrayLike</code> <p>Standard deviation of the forecast normal distribution.</p> required <p>Returns:</p> Name Type Description <code>crps</code> <code>array_like</code> <p>The CRPS between Normal(mu, sigma) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_normal(0.0, 0.1, 0.4)\n</code></pre>"},{"location":"api/crps/#ensemble-based-estimators","title":"Ensemble-based estimators","text":""},{"location":"api/crps/#scoringrules.crps_ensemble","title":"scoringrules.crps_ensemble","text":"<pre><code>crps_ensemble(\n    observations: ArrayLike,\n    forecasts: Array,\n    /,\n    axis: int = -1,\n    *,\n    sorted_ensemble: bool = False,\n    estimator: str = \"pwm\",\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Estimate the Continuous Ranked Probability Score (CRPS) for a finite ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the last axis.</p> required <code>axis</code> <code>int</code> <p>The axis corresponding to the ensemble. Default is the last axis.</p> <code>-1</code> <code>sorted_ensemble</code> <code>bool</code> <p>Boolean indicating whether the ensemble members are already in ascending order. Default is False.</p> <code>False</code> <code>estimator</code> <code>str</code> <p>Indicates the CRPS estimator to be used.</p> <code>'pwm'</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>crps</code> <code>ArrayLike</code> <p>The CRPS between the forecast ensemble and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_ensemble(obs, pred)\n</code></pre>"},{"location":"api/crps/#scoringrules.twcrps_ensemble","title":"scoringrules.twcrps_ensemble","text":"<pre><code>twcrps_ensemble(\n    observations: ArrayLike,\n    forecasts: Array,\n    v_func: tp.Callable[[ArrayLike], ArrayLike],\n    /,\n    axis: int = -1,\n    *,\n    estimator: str = \"pwm\",\n    sorted_ensemble: bool = False,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Estimate the Threshold-Weighted Continuous Ranked Probability Score (twCRPS) for a finite ensemble.</p> <p>Computation is performed using the ensemble representation of the twCRPS in Allen et al. (2022):</p> \\[ \\mathrm{twCRPS}(F_{ens}, y) = \\frac{1}{M} \\sum_{m = 1}^{M} |v(x_{m}) - v(y)| - \\frac{1}{2 M^{2}} \\sum_{m = 1}^{M} \\sum_{j = 1}^{M} |v(x_{m}) - v(x_{j})|,\\] <p>where \\(F_{ens}(x) = \\sum_{m=1}^{M} 1 \\{ x_{m} \\leq x \\}/M\\) is the empirical distribution function associated with an ensemble forecast \\(x_{1}, \\dots, x_{M}\\) with \\(M\\) members, and \\(v\\) is the chaining function used to target particular outcomes.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the last axis.</p> required <code>v_func</code> <code>Callable[[ArrayLike], ArrayLike]</code> <p>Chaining function used to emphasise particular outcomes. For example, a function that only considers values above a certain threshold \\(t\\) by projecting forecasts and observations to \\([t, \\inf)\\).</p> required <code>axis</code> <code>int</code> <p>The axis corresponding to the ensemble. Default is the last axis.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>twcrps</code> <code>ArrayLike</code> <p>The twCRPS between the forecast ensemble and obs for the chosen chaining function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt;\n&gt;&gt;&gt; def v_func(x):\n&gt;&gt;&gt;    return np.maximum(x, -1.0)\n&gt;&gt;&gt;\n&gt;&gt;&gt; sr.twcrps_ensemble(obs, pred, v_func)\n</code></pre>"},{"location":"api/crps/#scoringrules.owcrps_ensemble","title":"scoringrules.owcrps_ensemble","text":"<pre><code>owcrps_ensemble(\n    observations: ArrayLike,\n    forecasts: Array,\n    w_func: tp.Callable[[ArrayLike], ArrayLike],\n    /,\n    axis: int = -1,\n    *,\n    estimator: tp.Literal[\"nrg\"] = \"nrg\",\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Estimate the Outcome-Weighted Continuous Ranked Probability Score (owCRPS) for a finite ensemble.</p> <p>Computation is performed using the ensemble representation of the owCRPS in Allen et al. (2022):</p> \\[ \\mathrm{owCRPS}(F_{ens}, y) = \\frac{1}{M \\bar{w}} \\sum_{m = 1}^{M} |x_{m} - y|w(x_{m})w(y) - \\frac{1}{2 M^{2} \\bar{w}^{2}} \\sum_{m = 1}^{M} \\sum_{j = 1}^{M} |x_{m} - x_{j}|w(x_{m})w(x_{j})w(y),\\] <p>where \\(F_{ens}(x) = \\sum_{m=1}^{M} 1\\{ x_{m} \\leq x \\}/M\\) is the empirical distribution function associated with an ensemble forecast \\(x_{1}, \\dots, x_{M}\\) with \\(M\\) members, \\(w\\) is the chosen weight function, and \\(\\bar{w} = \\sum_{m=1}^{M}w(x_{m})/M\\).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the last axis.</p> required <code>w_func</code> <code>Callable[[ArrayLike], ArrayLike]</code> <p>Weight function used to emphasise particular outcomes.</p> required <code>axis</code> <code>int</code> <p>The axis corresponding to the ensemble. Default is the last axis.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>owcrps</code> <code>ArrayLike</code> <p>The owCRPS between the forecast ensemble and obs for the chosen weight function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt;\n&gt;&gt;&gt; def w_func(x):\n&gt;&gt;&gt;    return (x &gt; -1).astype(float)\n&gt;&gt;&gt;\n&gt;&gt;&gt; sr.owcrps_ensemble(obs, pred, w_func)\n</code></pre>"},{"location":"api/crps/#scoringrules.vrcrps_ensemble","title":"scoringrules.vrcrps_ensemble","text":"<pre><code>vrcrps_ensemble(\n    observations: ArrayLike,\n    forecasts: Array,\n    w_func: tp.Callable[[ArrayLike], ArrayLike],\n    /,\n    axis: int = -1,\n    *,\n    estimator: tp.Literal[\"nrg\"] = \"nrg\",\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Estimate the Vertically Re-scaled Continuous Ranked Probability Score (vrCRPS) for a finite ensemble.</p> <p>Computation is performed using the ensemble representation of the vrCRPS in Allen et al. (2022):</p> \\[ \\begin{split}     \\mathrm{vrCRPS}(F_{ens}, y) = &amp; \\frac{1}{M} \\sum_{m = 1}^{M} |x_{m} - y|w(x_{m})w(y) - \\frac{1}{2 M^{2}} \\sum_{m = 1}^{M} \\sum_{j = 1}^{M} |x_{m} - x_{j}|w(x_{m})w(x_{j}) \\\\         &amp; + \\left( \\frac{1}{M} \\sum_{m = 1}^{M} |x_{m}| w(x_{m}) - |y| w(y) \\right) \\left( \\frac{1}{M} \\sum_{m = 1}^{M} w(x_{m}) - w(y) \\right), \\end{split} \\] <p>where \\(F_{ens}(x) = \\sum_{m=1}^{M} 1 \\{ x_{m} \\leq x \\}/M\\) is the empirical distribution function associated with an ensemble forecast \\(x_{1}, \\dots, x_{M}\\) with \\(M\\) members, \\(w\\) is the chosen weight function, and \\(\\bar{w} = \\sum_{m=1}^{M}w(x_{m})/M\\).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the last axis.</p> required <code>w_func</code> <code>Callable[[ArrayLike], ArrayLike]</code> <p>Weight function used to emphasise particular outcomes.</p> required <code>axis</code> <code>int</code> <p>The axis corresponding to the ensemble. Default is the last axis.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>vrcrps</code> <code>ArrayLike</code> <p>The vrCRPS between the forecast ensemble and obs for the chosen weight function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt;\n&gt;&gt;&gt; def w_func(x):\n&gt;&gt;&gt;    return (x &gt; -1).astype(float)\n&gt;&gt;&gt;\n&gt;&gt;&gt; sr.vrcrps_ensemble(obs, pred, w_func)\n</code></pre>"},{"location":"api/crps/#quantile-based-estimators","title":"Quantile-based estimators","text":"<ol> <li> <p>Micha\u00ebl Zamo and Philippe Naveau. Estimation of the Continuous Ranked Probability Score with Limited Information and Applications to Ensemble Weather Forecasts. Mathematical Geosciences, 2018. URL: https://doi.org/10.1007/s11004-017-9709-7, doi:10.1007/s11004-017-9709-7.\u00a0\u21a9</p> </li> <li> <p>Alexander Jordan. Facets of forecast evaluation. PhD thesis, Karlsruher Institut f\u00fcr Technologie (KIT), 2016. doi:10.5445/IR/1000063629.\u00a0\u21a9</p> </li> </ol>"},{"location":"api/crps/#scoringrules.crps_quantile","title":"scoringrules.crps_quantile","text":"<pre><code>crps_quantile(\n    observations: ArrayLike,\n    forecasts: Array,\n    alpha: Array,\n    /,\n    axis: int = -1,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Approximate the CRPS from quantile predictions via the Pinball Loss.</p> <p>It is based on the notation in Berrisch &amp; Ziel, 2022</p> <p>The CRPS can be approximated as the mean pinball loss for all quantile forecasts \\(F_q\\) with level \\(q \\in Q\\):</p> \\[\\text{quantileCRPS} = \\frac{2}{|Q|} \\sum_{q \\in Q} PB_q\\] <p>where the pinball loss is defined as:</p> \\[\\text{PB}_q = \\begin{cases}     q(y - F_q) &amp;\\text{if} &amp; y \\geq F_q  \\\\     (1-q)(F_q - y) &amp;\\text{else.} &amp;  \\\\ \\end{cases} \\] <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the last axis.</p> required <code>alpha</code> <code>Array</code> <p>The percentile levels. We expect the quantile array to match the axis (see below) of the forecast array.</p> required <code>axis</code> <code>int</code> <p>The axis corresponding to the ensemble. Default is the last axis.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>qcrps</code> <code>Array</code> <p>An array of CRPS scores for each forecast, which should be averaged to get meaningful values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.crps_quantile(obs, fct, alpha)\n</code></pre>"},{"location":"api/energy/","title":"Energy Score","text":"<p>The energy score (ES) is a scoring rule for evaluating multivariate probabilistic forecasts. It is defined as</p> \\[\\text{ES}(F, \\mathbf{y})= \\mathbb{E} \\| \\mathbf{X} - \\mathbf{y} \\| - \\frac{1}{2} \\mathbb{E} \\| \\mathbf{X} - \\mathbf{X}^{\\prime} \\|, \\] <p>where \\(\\mathbf{y} \\in \\mathbb{R}^{d}\\) is the multivariate observation (\\(d &gt; 1\\)), and \\(\\mathbf{X}\\) and \\(\\mathbf{X}^{\\prime}\\) are independent random variables that follow the multivariate forecast distribution \\(F\\) (Gneiting and Raftery, 2007)<sup>1</sup>. If the dimension \\(d\\) were equal to one, the energy score would reduce to the continuous ranked probability score (CRPS).</p> <p>While multivariate probabilistic forecasts could belong to a parametric family of distributions, such as a multivariate normal distribution, it is more common in practice that these forecasts are ensemble forecasts; that is, the forecast is comprised of a predictive sample \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\), where each ensemble member \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M} \\in \\R^{d}\\).</p> <p>In this case, the expectations in the definition of the energy score can be replaced by sample means over the ensemble members, yielding the following representation of the energy score when evaluating an ensemble forecast \\(F_{ens}\\) with \\(M\\) members.</p> Weighted versions <p>The energy score provides a measure of overall forecast performance. However, it is often the case that certain outcomes are of more interest than others, making it desirable to assign more weight to these outcomes when evaluating forecast performance. This can be achieved using weighted scoring rules. Weighted scoring rules typically introduce a weight function into conventional scoring rules, and users can choose the weight function depending on what outcomes they want to emphasise. Allen et al. (2022)<sup>2</sup> discuss three weighted versions of the energy score. These are all available in <code>scoringrules</code>.</p> <p>Firstly, the outcome-weighted energy score (originally introduced by Holzmann and Klar (2014)<sup>3</sup>) is defined as</p> \\[\\text{owES}(F, \\mathbf{y}; w)= \\frac{1}{\\bar{w}} \\mathbb{E} \\| \\mathbf{X} - \\mathbf{y} \\| w(\\mathbf{X}) w(\\mathbf{y}) - \\frac{1}{2 \\bar{w}^{2}} \\mathbb{E} \\| \\mathbf{X} - \\mathbf{X}^{\\prime} \\| w(\\mathbf{X})w(\\mathbf{X}^{\\prime})w(\\mathbf{y}), \\] <p>where \\(w : \\mathbb{R}^{d} \\to [0, \\infty)\\) is the non-negative weight function used to target particular multivariate outcomes, and \\(\\bar{w} = \\mathbb{E}[w(X)]\\). As before, \\(\\mathbf{X}, \\mathbf{X}^{\\prime} \\sim F\\) are independent.</p> <p></p> <p>Secondly, Allen et al. (2022) introduced the threshold-weighted energy score as</p> \\[\\text{twES}(F, \\mathbf{y}; v)= \\mathbb{E} \\| v(\\mathbf{X}) - v(\\mathbf{y}) \\| - \\frac{1}{2} \\mathbb{E} \\| v(\\mathbf{X}) - v(\\mathbf{X}^{\\prime}) \\|, \\] <p>where \\(v : \\mathbb{R}^{d} \\to \\mathbb{R}^{d}\\) is a so-called chaining function. The threshold-weighted energy score transforms the forecasts and observations according to the chaining function \\(v\\), prior to calculating the unweighted energy score. Choosing a chaining function is generally more difficult than choosing a weight function when emphasising particular outcomes.</p> <p></p> <p>As an alternative, the vertically re-scaled energy score is defined as</p> \\[ \\begin{split}     \\text{vrES}(F, \\mathbf{y}; w, \\mathbf{x}_{0}) = &amp; \\mathbb{E} \\| \\mathbf{X} - \\mathbf{y} \\| w(\\mathbf{X}) w(\\mathbf{y}) \\\\ &amp; - \\frac{1}{2} \\mathbb{E} \\| \\mathbf{X} - \\mathbf{X}^{\\prime} \\| w(\\mathbf{X})w(\\mathbf{X}^{\\prime}) \\\\     &amp; + \\left( \\mathbb{E} \\| \\mathbf{X} - \\mathbf{x}_{0} \\| w(\\mathbf{X}) - \\| \\mathbf{y} - \\mathbf{x}_{0} \\| w(\\mathbf{y}) \\right) \\left(\\mathbb{E}[w(\\mathbf{X})] - w(\\mathbf{y}) \\right), \\end{split} \\] <p>where \\(w : \\mathbb{R}^{d} \\to [0, \\infty)\\) is the non-negative weight function used to target particular multivariate outcomes, and \\(\\mathbf{x}_{0} \\in \\mathbb{R}^{d}\\). Typically, \\(\\mathbf{x}_{0}\\) is chosen to be zero.</p> <p></p> <p>Each of these weighted energy scores targets particular outcomes in a different way. Further details regarding the differences between these scoring rules, as well as choices for the weight and chaining functions, can be found in Allen et al. (2022). The weighted energy scores can easily be computed for ensemble forecasts by replacing the expectations with sample means over the ensemble members.</p> <p></p> <ol> <li> <p>Tilmann Gneiting and Adrian E Raftery. Strictly Proper Scoring Rules, Prediction, and Estimation. Journal of the American Statistical Association, 2007. URL: https://doi.org/10.1198/016214506000001437, doi:10.1198/016214506000001437.\u00a0\u21a9</p> </li> <li> <p>Sam Allen, David Ginsbourger, and Johanna Ziegel. Evaluating forecasts for high-impact events using transformed kernel scores. arXiv preprint arXiv:2202.12732, 2022.\u00a0\u21a9</p> </li> <li> <p>Hajo Holzmann and Bernhard Klar. Focusing on regions of interest in forecast evaluation. The Annals of Applied Statistics, 11:2404\u20132431, 2017.\u00a0\u21a9</p> </li> </ol>"},{"location":"api/energy/#scoringrules.energy_score","title":"scoringrules.energy_score","text":"<pre><code>energy_score(\n    observations: Array,\n    forecasts: Array,\n    /,\n    m_axis: int = -2,\n    v_axis: int = -1,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Energy Score for a finite multivariate ensemble.</p> <p>The Energy Score is a multivariate scoring rule expressed as</p> \\[\\text{ES}(F_{ens}, \\mathbf{y})= \\frac{1}{M} \\sum_{m=1}^{M} \\| \\mathbf{x}_{m} -   \\mathbf{y} \\| - \\frac{1}{2 M^{2}} \\sum_{m=1}^{M} \\sum_{j=1}^{M} \\| \\mathbf{x}_{m} - \\mathbf{x}_{j} \\| \\] <p>where \\(||\\cdot||\\) is the euclidean norm over the input dimensions (the variables).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>Array</code> <p>The observed values, where the variables dimension is by default the last axis.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the second last axis and the variables dimension by the last axis.</p> required <code>m_axis</code> <code>int</code> <p>The axis corresponding to the ensemble dimension on the forecasts array. Defaults to -2.</p> <code>-2</code> <code>v_axis</code> <code>int</code> <p>The axis corresponding to the variables dimension on the forecasts array (or the observations array with an extra dimension on <code>m_axis</code>). Defaults to -1.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>energy_score</code> <code>Array of shape (...)</code> <p>The computed Energy Score.</p>"},{"location":"api/energy/#scoringrules.owenergy_score","title":"scoringrules.owenergy_score","text":"<pre><code>owenergy_score(\n    observations: Array,\n    forecasts: Array,\n    w_func: tp.Callable[[ArrayLike], ArrayLike],\n    /,\n    m_axis: int = -2,\n    v_axis: int = -1,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Outcome-Weighted Energy Score (owES) for a finite multivariate ensemble.</p> <p>Computation is performed using the ensemble representation of the owES in Allen et al. (2022):</p> \\[     \\mathrm{owES}(F_{ens}, \\mathbf{y}) = \\frac{1}{M \\bar{w}} \\sum_{m = 1}^{M} \\| \\mathbf{x}_{m} - \\mathbf{y} \\| w(\\mathbf{x}_{m}) w(\\mathbf{y}) - \\frac{1}{2 M^{2} \\bar{w}^{2}} \\sum_{m = 1}^{M} \\sum_{j = 1}^{M} \\| \\mathbf{x}_{m} - \\mathbf{x}_{j} \\| w(\\mathbf{x}_{m}) w(\\mathbf{x}_{j}) w(\\mathbf{y}), \\] <p>where \\(F_{ens}\\) is the ensemble forecast \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\) with \\(M\\) members, \\(\\| \\cdotp \\|\\) is the Euclidean distance, \\(w\\) is the chosen weight function, and \\(\\bar{w} = \\sum_{m=1}^{M}w(\\mathbf{x}_{m})/M\\).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>Array</code> <p>The observed values, where the variables dimension is by default the last axis.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the second last axis and the variables dimension by the last axis.</p> required <code>w_func</code> <code>Callable[[ArrayLike], ArrayLike]</code> <p>Weight function used to emphasise particular outcomes.</p> required <code>m_axis</code> <code>int</code> <p>The axis corresponding to the ensemble dimension. Defaults to -2.</p> <code>-2</code> <code>v_axis</code> <code>int</code> <p>The axis corresponding to the variables dimension. Defaults to -1.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>owenergy_score</code> <code>ArrayLike of shape (...)</code> <p>The computed Outcome-Weighted Energy Score.</p>"},{"location":"api/energy/#scoringrules.twenergy_score","title":"scoringrules.twenergy_score","text":"<pre><code>twenergy_score(\n    observations: Array,\n    forecasts: Array,\n    v_func: tp.Callable[[ArrayLike], ArrayLike],\n    /,\n    m_axis: int = -2,\n    v_axis: int = -1,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Threshold-Weighted Energy Score (twES) for a finite multivariate ensemble.</p> <p>Computation is performed using the ensemble representation of the twES in Allen et al. (2022):</p> \\[     \\mathrm{twES}(F_{ens}, \\mathbf{y}) = \\frac{1}{M} \\sum_{m = 1}^{M} \\| v(\\mathbf{x}_{m}) - v(\\mathbf{y}) \\| - \\frac{1}{2 M^{2}} \\sum_{m = 1}^{M} \\sum_{j = 1}^{M} \\| v(\\mathbf{x}_{m}) - v(\\mathbf{x}_{j}) \\|, \\] <p>where \\(F_{ens}\\) is the ensemble forecast \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\) with \\(M\\) members, \\(\\| \\cdotp \\|\\) is the Euclidean distance, and \\(v\\) is the chaining function used to target particular outcomes.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>Array</code> <p>The observed values, where the variables dimension is by default the last axis.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the second last axis and the variables dimension by the last axis.</p> required <code>v_func</code> <code>Callable[[ArrayLike], ArrayLike]</code> <p>Chaining function used to emphasise particular outcomes.</p> required <code>m_axis</code> <code>int</code> <p>The axis corresponding to the ensemble dimension. Defaults to -2.</p> <code>-2</code> <code>v_axis</code> <code>int</code> <p>The axis corresponding to the variables dimension. Defaults to -1.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>twenergy_score</code> <code>ArrayLike of shape (...)</code> <p>The computed Threshold-Weighted Energy Score.</p>"},{"location":"api/energy/#scoringrules.vrenergy_score","title":"scoringrules.vrenergy_score","text":"<pre><code>vrenergy_score(\n    observations: Array,\n    forecasts: Array,\n    w_func: tp.Callable[[ArrayLike], ArrayLike],\n    /,\n    *,\n    m_axis: int = -2,\n    v_axis: int = -1,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Vertically Re-scaled Energy Score (vrES) for a finite multivariate ensemble.</p> <p>Computation is performed using the ensemble representation of the vrES in Allen et al. (2022):</p> \\[ \\begin{split}     \\mathrm{vrES}(F_{ens}, \\mathbf{y}) = &amp; \\frac{1}{M} \\sum_{m = 1}^{M} \\| \\mathbf{x}_{m} - \\mathbf{y} \\| w(\\mathbf{x}_{m}) w(\\mathbf{y}) - \\frac{1}{2 M^{2}} \\sum_{m = 1}^{M} \\sum_{j = 1}^{M} \\| \\mathbf{x}_{m} - \\mathbf{x}_{j} \\| w(\\mathbf{x}_{m}) w(\\mathbf{x_{j}}) \\\\         &amp; + \\left( \\frac{1}{M} \\sum_{m = 1}^{M} \\| \\mathbf{x}_{m} \\| w(\\mathbf{x}_{m}) - \\| \\mathbf{y} \\| w(\\mathbf{y}) \\right) \\left( \\frac{1}{M} \\sum_{m = 1}^{M} w(\\mathbf{x}_{m}) - w(\\mathbf{y}) \\right), \\end{split} \\] <p>where \\(F_{ens}\\) is the ensemble forecast \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\) with \\(M\\) members, and \\(w\\) is the weight function used to target particular outcomes.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>Array</code> <p>The observed values, where the variables dimension is by default the last axis.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the second last axis and the variables dimension by the last axis.</p> required <code>w_func</code> <code>Callable[[ArrayLike], ArrayLike]</code> <p>Weight function used to emphasise particular outcomes.</p> required <code>m_axis</code> <code>int</code> <p>The axis corresponding to the ensemble dimension. Defaults to -2.</p> <code>-2</code> <code>v_axis</code> <code>int</code> <p>The axis corresponding to the variables dimension. Defaults to -1.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>vrenergy_score</code> <code>ArrayLike of shape (...)</code> <p>The computed Vertically Re-scaled Energy Score.</p>"},{"location":"api/error_spread/","title":"Error Spread Score","text":"<p>The error spread score (Christensen et al., 2015) is given by:</p> \\[ESS = \\left(s^2 - e^2 - e \\cdot s \\cdot g\\right)^2\\] <p>where the mean \\(m\\), variance \\(s^2\\), and skewness \\(g\\) of the ensemble forecast of size \\(F\\) are computed as follows:</p> \\[m = \\frac{1}{F} \\sum_{f=1}^{F} X_f, \\quad s^2 = \\frac{1}{F-1} \\sum_{f=1}^{F} (X_f - m)^2, \\quad g = \\frac{F}{(F-1)(F-2)} \\sum_{f=1}^{F} \\left(\\frac{X_f - m}{s}\\right)^3\\] <p>The error in the ensemble mean \\(e\\) is calculated as \\(e = m - y\\), where \\(y\\) is the observed value.</p>"},{"location":"api/error_spread/#scoringrules.error_spread_score","title":"scoringrules.error_spread_score","text":"<pre><code>error_spread_score(\n    observations: ArrayLike,\n    forecasts: Array,\n    /,\n    axis: int = -1,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the error-spread score (Christensen et al., 2015) for a finite ensemble.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the last axis.</p> required <code>axis</code> <code>int</code> <p>The axis corresponding to the ensemble. Default is the last axis.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Type Description <code>-Array</code> <p>An array of error spread scores for each ensemble forecast, which should be averaged to get meaningful values.</p>"},{"location":"api/interval/","title":"Interval Score","text":""},{"location":"api/interval/#scoringrules.interval_score","title":"scoringrules.interval_score","text":"<pre><code>interval_score(\n    obs: ArrayLike,\n    lower: ArrayLike,\n    upper: ArrayLike,\n    alpha: ArrayLike,\n    *,\n    backend: Backend = None\n) -&gt; Array\n</code></pre> <p>Compute the Interval Score or Winkler Score.</p> <p>The interval score (Gneiting &amp; Raftery, 2012) is defined as</p> \\[ \\text{IS} =     \\begin{cases}     (u - l) + \\frac{2}{\\alpha}(l - y)  &amp; \\text{for } y &lt; l \\\\     (u - l)                            &amp; \\text{for } l \\leq y \\leq u \\\\     (u - l) + \\frac{2}{\\alpha}(y - u)  &amp; \\text{for } y &gt; u. \\\\     \\end{cases} \\] <p>for an \\(1 - \\alpha\\) prediction interval of \\([l, u]\\) and the true value \\(y\\).</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>ArrayLike</code> <p>The observations as a scalar or array of values.</p> required <code>lower</code> <code>ArrayLike</code> <p>The predicted lower bound of the PI as a scalar or array of values.</p> required <code>upper</code> <code>ArrayLike</code> <p>The predicted upper bound of the PI as a scalar or array of values.</p> required <code>alpha</code> <code>ArrayLike</code> <p>The 1 - alpha level for the PI as a scalar or array of values.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>Array</code> <p>Array with the interval score for the input values.</p> <p>Raises:</p> Type Description <code>ValueError:</code> <p>If the lower and upper bounds do not have the same shape or if the number of PIs does not match the number of alpha levels.</p> Notes <p>Given an <code>obs</code> array of shape <code>(...,)</code>, in the case when multiple PIs are evaluated <code>alpha</code> is an array of shape <code>(K,)</code>, then <code>lower</code> and <code>upper</code> must have shape <code>(...,K)</code> and the output will have shape <code>(...,K)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.interval_score(0.1, 0.0, 0.4, 0.5)\n0.4\n</code></pre> <pre><code>&gt;&gt;&gt; sr.interval_score(\n...     obs=np.array([0.1, 0.2, 0.3]),\n...     lower=np.array([0.0, 0.1, 0.2]),\n...     upper=np.array([0.4, 0.3, 0.5]),\n...     alpha=0.5,\n... )\narray([0.4, 0.2, 0.4])\n</code></pre> <pre><code>&gt;&gt;&gt; sr.interval_score(\n...     obs=np.random.uniform(size=(10,)),\n...     lower=np.ones((10,5)) * 0.2,\n...     upper=np.ones((10,5)) * 0.8,\n...     alpha=np.linspace(0.1, 0.9, 5),\n... ).shape\n(10, 5)\n</code></pre>"},{"location":"api/interval/#scoringrules.weighted_interval_score","title":"scoringrules.weighted_interval_score","text":"<pre><code>weighted_interval_score(\n    obs: ArrayLike,\n    median: Array,\n    lower: Array,\n    upper: Array,\n    alpha: Array,\n    /,\n    w_median: Optional[float] = None,\n    w_alpha: Optional[Array] = None,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the weighted interval score (WIS).</p> <p>The WIS (Bracher et al., 2022) is defined as</p> \\[ \\text{WIS}_{\\alpha_{0:K}}(F, y) = \\frac{1}{K+0.5}(w_0 \\times |y - m| + \\sum_{k=1}^K (w_k \\times IS_{\\alpha_k}(F, y))) \\] <p>where \\(m\\) denotes the median prediction, \\(w_0\\) denotes the weight of the median prediction, \\(IS_{\\alpha_k}(F, y)\\) denotes the interval score for the \\(1 - \\alpha\\) prediction interval and \\(w_k\\) is the according weight. The WIS is calculated for a set of (central) PIs and the predictive median. The weights are an optional parameter and default weight is the canonical weight \\(w_k = \\frac{2}{\\alpha_k}\\) and \\(w_0 = 0.5\\). For these weights, it holds that:</p> \\[ \\text{WIS}_{\\alpha_{0:K}}(F, y) \\approx \\text{CRPS}(F, y). \\] <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>ArrayLike</code> <p>The observations as a scalar or array of shape <code>(...,)</code>.</p> required <code>median</code> <code>Array</code> <p>The predicted median of the distribution as a scalar or array of shape <code>(...,)</code>.</p> required <code>lower</code> <code>Array</code> <p>The predicted lower bound of the PI. If <code>alpha</code> is an array of shape <code>(K,)</code>, <code>lower</code> must have shape <code>(...,K)</code>.</p> required <code>upper</code> <code>Array</code> <p>The predicted upper bound of the PI. If <code>alpha</code> is an array of shape <code>(K,)</code>, <code>upper</code> must have shape <code>(...,K)</code>.</p> required <code>alpha</code> <code>Array</code> <p>The 1 - alpha level for the prediction intervals as an array of shape <code>(K,)</code>.</p> required <code>w_median</code> <code>Optional[float]</code> <p>The weight for the median prediction. Defaults to 0.5.</p> <code>None</code> <code>w_alpha</code> <code>Optional[Array]</code> <p>The weights for the PI. Defaults to <code>2/alpha</code>.</p> <code>None</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>Array</code> <p>An array of interval scores with the same shape as <code>obs</code>.</p>"},{"location":"api/kernels/","title":"Kernel scores","text":""},{"location":"api/kernels/#scoringrules.gksuv_ensemble","title":"scoringrules.gksuv_ensemble","text":"<pre><code>gksuv_ensemble(\n    observations: ArrayLike,\n    forecasts: Array,\n    /,\n    axis: int = -1,\n    *,\n    estimator: str = \"nrg\",\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the univariate Gaussian Kernel Score (GKS) for a finite ensemble.</p> <p>The GKS is the kernel score associated with the Gaussian kernel</p> \\[ k(x_{1}, x_{2}) = \\exp \\left(- \\frac{(x_{1} - x_{2})^{2}}{2} \\right). \\] <p>Given an ensemble forecast \\(F_{ens}\\) comprised of members \\(x_{1}, \\dots, x_{M}\\), the GKS is</p> \\[\\text{GKS}(F_{ens}, y)= - \\frac{1}{M} \\sum_{m=1}^{M} k(x_{m}, y) + \\frac{1}{2 M^{2}} \\sum_{m=1}^{M} \\sum_{j=1}^{M} k(x_{m}, x_{j}) + \\frac{1}{2}k(y, y) \\] <p>If the fair estimator is to be used, then \\(M^{2}\\) in the second component of the right-hand-side is replaced with \\(M(M - 1)\\).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the last axis.</p> required <code>axis</code> <code>int</code> <p>The axis corresponding to the ensemble. Default is the last axis.</p> <code>-1</code> <code>estimator</code> <code>str</code> <p>Indicates the estimator to be used.</p> <code>'nrg'</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>Array</code> <p>The GKS between the forecast ensemble and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.gks_ensemble(obs, pred)\n</code></pre>"},{"location":"api/kernels/#scoringrules.twgksuv_ensemble","title":"scoringrules.twgksuv_ensemble","text":"<pre><code>twgksuv_ensemble(\n    observations: ArrayLike,\n    forecasts: Array,\n    v_func: tp.Callable[[ArrayLike], ArrayLike],\n    /,\n    axis: int = -1,\n    *,\n    estimator: str = \"nrg\",\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Threshold-Weighted univariate Gaussian Kernel Score (GKS) for a finite ensemble.</p> <p>Computation is performed using the ensemble representation of threshold-weighted kernel scores in Allen et al. (2022).</p> \\[ \\mathrm{twGKS}(F_{ens}, y) = - \\frac{1}{M} \\sum_{m = 1}^{M} k(v(x_{m}), v(y)) + \\frac{1}{2 M^{2}} \\sum_{m = 1}^{M} \\sum_{j = 1}^{M} k(v(x_{m}), v(x_{j})) + \\frac{1}{2} k(v(y), v(y)), \\] <p>where \\(F_{ens}(x) = \\sum_{m=1}^{M} 1 \\{ x_{m} \\leq x \\}/M\\) is the empirical distribution function associated with an ensemble forecast \\(x_{1}, \\dots, x_{M}\\) with \\(M\\) members, \\(v\\) is the chaining function used to target particular outcomes, and</p> \\[ k(x_{1}, x_{2}) = \\exp \\left(- \\frac{(x_{1} - x_{2})^{2}}{2} \\right) \\] <p>is the Gaussian kernel.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the last axis.</p> required <code>v_func</code> <code>Callable[[ArrayLike], ArrayLike]</code> <p>Chaining function used to emphasise particular outcomes. For example, a function that only considers values above a certain threshold \\(t\\) by projecting forecasts and observations to \\([t, \\inf)\\).</p> required <code>axis</code> <code>int</code> <p>The axis corresponding to the ensemble. Default is the last axis.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>twgks</code> <code>ArrayLike</code> <p>The twGKS between the forecast ensemble and obs for the chosen chaining function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt;\n&gt;&gt;&gt; def v_func(x):\n&gt;&gt;&gt;    return np.maximum(x, -1.0)\n&gt;&gt;&gt;\n&gt;&gt;&gt; sr.twgksuv_ensemble(obs, pred, v_func)\n</code></pre>"},{"location":"api/kernels/#scoringrules.owgksuv_ensemble","title":"scoringrules.owgksuv_ensemble","text":"<pre><code>owgksuv_ensemble(\n    observations: ArrayLike,\n    forecasts: Array,\n    w_func: tp.Callable[[ArrayLike], ArrayLike],\n    /,\n    axis: int = -1,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the univariate Outcome-Weighted Gaussian Kernel Score (owGKS) for a finite ensemble.</p> <p>Computation is performed using the ensemble representation of the owCRPS in Allen et al. (2022):</p> \\[ \\mathrm{owGKS}(F_{ens}, y) = -\\frac{1}{M \\bar{w}} \\sum_{m = 1}^{M} k(x_{m}, y)w(x_{m})w(y) - \\frac{1}{2 M^{2} \\bar{w}^{2}} \\sum_{m = 1}^{M} \\sum_{j = 1}^{M} k(x_{m}, x_{j})w(x_{m})w(x_{j})w(y),\\] <p>where \\(F_{ens}(x) = \\sum_{m=1}^{M} 1\\{ x_{m} \\leq x \\}/M\\) is the empirical distribution function associated with an ensemble forecast \\(x_{1}, \\dots, x_{M}\\) with \\(M\\) members, \\(w\\) is the chosen weight function, \\(\\bar{w} = \\sum_{m=1}^{M}w(x_{m})/M\\), and</p> \\[ k(x_{1}, x_{2}) = \\exp \\left(- \\frac{(x_{1} - x_{2})^{2}}{2} \\right) \\] <p>is the Gaussian kernel.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the last axis.</p> required <code>w_func</code> <code>Callable[[ArrayLike], ArrayLike]</code> <p>Weight function used to emphasise particular outcomes.</p> required <code>axis</code> <code>int</code> <p>The axis corresponding to the ensemble. Default is the last axis.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The owGKS between the forecast ensemble and obs for the chosen weight function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt;\n&gt;&gt;&gt; def w_func(x):\n&gt;&gt;&gt;    return (x &gt; -1).astype(float)\n&gt;&gt;&gt;\n&gt;&gt;&gt; sr.owgksuv_ensemble(obs, pred, w_func)\n</code></pre>"},{"location":"api/kernels/#scoringrules.vrgksuv_ensemble","title":"scoringrules.vrgksuv_ensemble","text":"<pre><code>vrgksuv_ensemble(\n    observations: ArrayLike,\n    forecasts: Array,\n    w_func: tp.Callable[[ArrayLike], ArrayLike],\n    /,\n    axis: int = -1,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Estimate the Vertically Re-scaled Gaussian Kernel Score (vrGKS) for a finite ensemble.</p> <p>Computation is performed using the ensemble representation of vertically re-scaled kernel scores in Allen et al. (2022):</p> \\[ \\mathrm{vrGKS}(F_{ens}, y) = - \\frac{1}{M} \\sum_{m = 1}^{M} k(x_{m}, y)w(x_{m})w(y) + \\frac{1}{2 M^{2}} \\sum_{m = 1}^{M} \\sum_{j = 1}^{M} k(x_{m}, x_{j})w(x_{m})w(x_{j}) + \\frac{1}{2} k(y, y)w(y)w(y), \\] <p>where \\(F_{ens}(x) = \\sum_{m=1}^{M} 1 \\{ x_{m} \\leq x \\}/M\\) is the empirical distribution function associated with an ensemble forecast \\(x_{1}, \\dots, x_{M}\\) with \\(M\\) members, \\(w\\) is the chosen weight function, \\(\\bar{w} = \\sum_{m=1}^{M}w(x_{m})/M\\), and</p> \\[ k(x_{1}, x_{2}) = \\exp \\left(- \\frac{(x_{1} - x_{2})^{2}}{2} \\right) \\] <p>is the Gaussian kernel.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the last axis.</p> required <code>w_func</code> <code>Callable[[ArrayLike], ArrayLike]</code> <p>Weight function used to emphasise particular outcomes.</p> required <code>axis</code> <code>int</code> <p>The axis corresponding to the ensemble. Default is the last axis.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The vrGKS between the forecast ensemble and obs for the chosen weight function.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt;\n&gt;&gt;&gt; def w_func(x):\n&gt;&gt;&gt;    return (x &gt; -1).astype(float)\n&gt;&gt;&gt;\n&gt;&gt;&gt; sr.vrgksuv_ensemble(obs, pred, w_func)\n</code></pre>"},{"location":"api/kernels/#scoringrules.gksmv_ensemble","title":"scoringrules.gksmv_ensemble","text":"<pre><code>gksmv_ensemble(\n    observations: Array,\n    forecasts: Array,\n    /,\n    m_axis: int = -2,\n    v_axis: int = -1,\n    *,\n    estimator: str = \"nrg\",\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the multivariate Gaussian Kernel Score (GKS) for a finite ensemble.</p> <p>The GKS is the kernel score associated with the Gaussian kernel</p> \\[ k(x_{1}, x_{2}) = \\exp \\left(- \\frac{ \\| x_{1} - x_{2} \\| ^{2}}{2} \\right), \\] <p>where $ | \\cdot |$ is the euclidean norm.</p> <p>Given an ensemble forecast \\(F_{ens}\\) comprised of multivariate members \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\), the GKS is</p> \\[\\text{GKS}(F_{ens}, y)= - \\frac{1}{M} \\sum_{m=1}^{M} k(\\mathbf{x}_{m}, \\mathbf{y}) + \\frac{1}{2 M^{2}} \\sum_{m=1}^{M} \\sum_{j=1}^{M} k(\\mathbf{x}_{m}, \\mathbf{x}_{j}) + \\frac{1}{2}k(y, y) \\] <p>If the fair estimator is to be used, then \\(M^{2}\\) in the second component of the right-hand-side is replaced with \\(M(M - 1)\\).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>Array</code> <p>The observed values, where the variables dimension is by default the last axis.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the second last axis and the variables dimension by the last axis.</p> required <code>m_axis</code> <code>int</code> <p>The axis corresponding to the ensemble dimension on the forecasts array. Defaults to -2.</p> <code>-2</code> <code>v_axis</code> <code>int</code> <p>The axis corresponding to the variables dimension on the forecasts array (or the observations array with an extra dimension on <code>m_axis</code>). Defaults to -1.</p> <code>-1</code> <code>estimator</code> <code>str</code> <p>Indicates the estimator to be used.</p> <code>'nrg'</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>Array</code> <p>The GKS between the forecast ensemble and obs.</p>"},{"location":"api/kernels/#scoringrules.twgksmv_ensemble","title":"scoringrules.twgksmv_ensemble","text":"<pre><code>twgksmv_ensemble(\n    observations: Array,\n    forecasts: Array,\n    v_func: tp.Callable[[ArrayLike], ArrayLike],\n    /,\n    m_axis: int = -2,\n    v_axis: int = -1,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Threshold-Weighted Gaussian Kernel Score (twGKS) for a finite multivariate ensemble.</p> <p>Computation is performed using the ensemble representation of threshold-weighted kernel scores in Allen et al. (2022):</p> \\[ \\mathrm{twGKS}(F_{ens}, y) = - \\frac{1}{M} \\sum_{m = 1}^{M} k(v(x_{m}), v(y)) + \\frac{1}{2 M^{2}} \\sum_{m = 1}^{M} \\sum_{j = 1}^{M} k(v(x_{m}), v(x_{j})) + \\frac{1}{2} k(v(y), v(y)), \\] <p>where \\(F_{ens}\\) is the ensemble forecast \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\) with \\(M\\) members, \\(\\| \\cdotp \\|\\) is the Euclidean distance, \\(v\\) is the chaining function used to target particular outcomes, and</p> \\[ k(x_{1}, x_{2}) = \\exp \\left(- \\frac{(x_{1} - x_{2})^{2}}{2} \\right) \\] <p>is the Gaussian kernel.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>Array</code> <p>The observed values, where the variables dimension is by default the last axis.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the second last axis and the variables dimension by the last axis.</p> required <code>v_func</code> <code>Callable[[ArrayLike], ArrayLike]</code> <p>Chaining function used to emphasise particular outcomes.</p> required <code>m_axis</code> <code>int</code> <p>The axis corresponding to the ensemble dimension. Defaults to -2.</p> <code>-2</code> <code>v_axis</code> <code>int</code> <p>The axis corresponding to the variables dimension. Defaults to -1.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike of shape (...)</code> <p>The computed Threshold-Weighted Gaussian Kernel Score.</p>"},{"location":"api/kernels/#scoringrules.owgksmv_ensemble","title":"scoringrules.owgksmv_ensemble","text":"<pre><code>owgksmv_ensemble(\n    observations: Array,\n    forecasts: Array,\n    w_func: tp.Callable[[ArrayLike], ArrayLike],\n    /,\n    m_axis: int = -2,\n    v_axis: int = -1,\n    *,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the multivariate Outcome-Weighted Gaussian Kernel Score (owGKS) for a finite ensemble.</p> <p>Given an ensemble forecast \\(F_{ens}\\) comprised of multivariate members \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\), the GKS is</p> \\[\\text{GKS}(F_{ens}, y)= - \\frac{1}{M} \\sum_{m=1}^{M} k(\\mathbf{x}_{m}, \\mathbf{y}) + \\frac{1}{2 M^{2}} \\sum_{m=1}^{M} \\sum_{j=1}^{M} k(\\mathbf{x}_{m}, \\mathbf{x}_{j}) + \\frac{1}{2}k(y, y) \\] <p>If the fair estimator is to be used, then \\(M^{2}\\) in the second component of the right-hand-side is replaced with \\(M(M - 1)\\).</p> <p>Computation is performed using the ensemble representation of outcome-weighted kernel scores in Allen et al. (2022):</p> \\[     \\mathrm{owGKS}(F_{ens}, \\mathbf{y}) = - \\frac{1}{M \\bar{w}} \\sum_{m = 1}^{M} k(\\mathbf{x}_{m}, \\mathbf{y}) w(\\mathbf{x}_{m}) w(\\mathbf{y}) + \\frac{1}{2 M^{2} \\bar{w}^{2}} \\sum_{m = 1}^{M} \\sum_{j = 1}^{M} k(\\mathbf{x}_{m}, \\mathbf{x}_{j}) w(\\mathbf{x}_{m}) w(\\mathbf{x}_{j}) w(\\mathbf{y}) + \\frac{1}{2}k(\\mathbf{y}, \\mathbf{y})w(\\mathbf{y}), \\] <p>where \\(F_{ens}\\) is the ensemble forecast \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\) with \\(M\\) members, \\(\\| \\cdotp \\|\\) is the Euclidean distance, \\(w\\) is the chosen weight function, \\(\\bar{w} = \\sum_{m=1}^{M}w(\\mathbf{x}_{m})/M\\), and</p> \\[ k(x_{1}, x_{2}) = \\exp \\left(- \\frac{ \\| x_{1} - x_{2} \\| ^{2}}{2} \\right), \\] <p>is the multivariate Gaussian kernel, with $ | \\cdot |$ the Euclidean norm.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>Array</code> <p>The observed values, where the variables dimension is by default the last axis.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the second last axis and the variables dimension by the last axis.</p> required <code>w_func</code> <code>Callable[[ArrayLike], ArrayLike]</code> <p>Weight function used to emphasise particular outcomes.</p> required <code>m_axis</code> <code>int</code> <p>The axis corresponding to the ensemble dimension. Defaults to -2.</p> <code>-2</code> <code>v_axis</code> <code>int</code> <p>The axis corresponding to the variables dimension. Defaults to -1.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike of shape (...)</code> <p>The computed Outcome-Weighted GKS.</p>"},{"location":"api/kernels/#scoringrules.vrgksmv_ensemble","title":"scoringrules.vrgksmv_ensemble","text":"<pre><code>vrgksmv_ensemble(\n    observations: Array,\n    forecasts: Array,\n    w_func: tp.Callable[[ArrayLike], ArrayLike],\n    /,\n    *,\n    m_axis: int = -2,\n    v_axis: int = -1,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Vertically Re-scaled Gaussian Kernel Score (vrGKS) for a finite multivariate ensemble.</p> <p>Computation is performed using the ensemble representation of vertically re-scaled kernel scores  in Allen et al. (2022):</p> \\[ \\mathrm{vrGKS}(F_{ens}, \\mathbf{y}) = &amp; - \\frac{1}{M} \\sum_{m = 1}^{M} k(\\mathbf{x}_{m}, \\mathbf{y}) w(\\mathbf{x}_{m}) w(\\mathbf{y}) + \\frac{1}{2 M^{2}} \\sum_{m = 1}^{M} \\sum_{j = 1}^{M} k(\\mathbf{x}_{m}, \\mathbf{x}_{j}) w(\\mathbf{x}_{m}) w(\\mathbf{x_{j}}) + \\frac{1}{2} k(y, y)w(y)w(y), \\] <p>where \\(F_{ens}\\) is the ensemble forecast \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\) with \\(M\\) members, \\(w\\) is the weight function used to target particular outcomes, and</p> \\[ k(x_{1}, x_{2}) = \\exp \\left(- \\frac{ \\| x_{1} - x_{2} \\| ^{2}}{2} \\right), \\] <p>is the multivariate Gaussian kernel, with $ | \\cdot |$ the Euclidean norm.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>Array</code> <p>The observed values, where the variables dimension is by default the last axis.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the second last axis and the variables dimension by the last axis.</p> required <code>w_func</code> <code>Callable[[ArrayLike], ArrayLike]</code> <p>Weight function used to emphasise particular outcomes.</p> required <code>m_axis</code> <code>int</code> <p>The axis corresponding to the ensemble dimension. Defaults to -2.</p> <code>-2</code> <code>v_axis</code> <code>int</code> <p>The axis corresponding to the variables dimension. Defaults to -1.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike of shape (...)</code> <p>The computed Vertically Re-scaled Gaussian Kernel Score.</p>"},{"location":"api/logarithmic/","title":"Logarithmic Score","text":""},{"location":"api/logarithmic/#scoringrules.logs_beta","title":"scoringrules.logs_beta","text":"<pre><code>logs_beta(\n    observation: ArrayLike,\n    a: ArrayLike,\n    b: ArrayLike,\n    /,\n    lower: ArrayLike = 0.0,\n    upper: ArrayLike = 1.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the beta distribution.</p> <p>This score is equivalent to the negative log likelihood of the beta distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>a</code> <code>ArrayLike</code> <p>First shape parameter of the forecast beta distribution.</p> required <code>b</code> <code>ArrayLike</code> <p>Second shape parameter of the forecast beta distribution.</p> required <code>lower</code> <code>ArrayLike</code> <p>Lower bound of the forecast beta distribution.</p> <code>0.0</code> <code>upper</code> <code>ArrayLike</code> <p>Upper bound of the forecast beta distribution.</p> <code>1.0</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between Beta(a, b) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_beta(0.3, 0.7, 1.1)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_binomial","title":"scoringrules.logs_binomial","text":"<pre><code>logs_binomial(\n    observation: ArrayLike,\n    n: ArrayLike,\n    prob: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the binomial distribution.</p> <p>This score is equivalent to the negative log likelihood of the binomial distribution</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>n</code> <code>ArrayLike</code> <p>Size parameter of the forecast binomial distribution as an integer or array of integers.</p> required <code>prob</code> <code>ArrayLike</code> <p>Probability parameter of the forecast binomial distribution as a float or array of floats.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between Binomial(n, prob) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_binomial(4, 10, 0.5)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_ensemble","title":"scoringrules.logs_ensemble","text":"<pre><code>logs_ensemble(\n    observations: ArrayLike,\n    forecasts: Array,\n    /,\n    axis: int = -1,\n    *,\n    bw: ArrayLike = None,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Estimate the Logarithmic score for a finite ensemble via kernel density estimation.</p> <p>Gaussian kernel density estimation is used to convert the finite ensemble to a mixture of normal distributions, with the component distributions centred at each ensemble member, with scale equal to the bandwidth parameter 'bw'.</p> <p>The log score for the ensemble forecast is then the log score for the mixture of normal distributions.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the last axis.</p> required <code>axis</code> <code>int</code> <p>The axis corresponding to the ensemble. Default is the last axis.</p> <code>-1</code> <code>bw</code> <code>ArrayLike</code> <p>The bandwidth parameter for each forecast ensemble. If not given, estimated using Silverman's rule of thumb.</p> <code>None</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>Array</code> <p>The LS between the forecast ensemble and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_ensemble(obs, pred)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_exponential","title":"scoringrules.logs_exponential","text":"<pre><code>logs_exponential(\n    observation: ArrayLike,\n    rate: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the exponential distribution.</p> <p>This score is equivalent to the negative log likelihood of the exponential distribution</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>rate</code> <code>ArrayLike</code> <p>Rate parameter of the forecast exponential distribution.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between Exp(rate) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_exponential(0.8, 3.0)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_exponential2","title":"scoringrules.logs_exponential2","text":"<pre><code>logs_exponential2(\n    observation: ArrayLike,\n    /,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the exponential distribution with location and scale parameters.</p> <p>This score is equivalent to the negative log likelihood of the exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast exponential distribution.</p> <code>0.0</code> <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast exponential distribution.</p> <code>1.0</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between obs and Exp2(location, scale).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_exponential2(0.2, 0.0, 1.0)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_2pexponential","title":"scoringrules.logs_2pexponential","text":"<pre><code>logs_2pexponential(\n    observation: ArrayLike,\n    scale1: ArrayLike,\n    scale2: ArrayLike,\n    location: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the two-piece exponential distribution.</p> <p>This score is equivalent to the negative log likelihood of the two-piece exponential distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>scale1</code> <code>ArrayLike</code> <p>First scale parameter of the forecast two-piece exponential distribution.</p> required <code>scale2</code> <code>ArrayLike</code> <p>Second scale parameter of the forecast two-piece exponential distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast two-piece exponential distribution.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between 2pExp(sigma1, sigma2, location) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_2pexponential(0.8, 3.0, 1.4, 0.0)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_gamma","title":"scoringrules.logs_gamma","text":"<pre><code>logs_gamma(\n    observation: ArrayLike,\n    shape: ArrayLike,\n    /,\n    rate: ArrayLike | None = None,\n    *,\n    scale: ArrayLike | None = None,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the gamma distribution.</p> <p>This score is equivalent to the negative log likelihood of the gamma distribution</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>shape</code> <code>ArrayLike</code> <p>Shape parameter of the forecast gamma distribution.</p> required <code>rate</code> <code>ArrayLike | None</code> <p>Rate parameter of the forecast gamma distribution.</p> <code>None</code> <code>scale</code> <code>ArrayLike | None</code> <p>Scale parameter of the forecast gamma distribution, where <code>scale = 1 / rate</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between obs and Gamma(shape, rate).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_gamma(0.2, 1.1, 0.1)\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both <code>rate</code> and <code>scale</code> are provided, or if neither is provided.</p>"},{"location":"api/logarithmic/#scoringrules.logs_gev","title":"scoringrules.logs_gev","text":"<pre><code>logs_gev(\n    observation: ArrayLike,\n    shape: ArrayLike,\n    /,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the generalised extreme value (GEV) distribution.</p> <p>This score is equivalent to the negative log likelihood of the GEV distribution</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>shape</code> <code>ArrayLike</code> <p>Shape parameter of the forecast GEV distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast GEV distribution.</p> <code>0.0</code> <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast GEV distribution.</p> <code>1.0</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between obs and GEV(shape, location, scale).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_gev(0.3, 0.1)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_gpd","title":"scoringrules.logs_gpd","text":"<pre><code>logs_gpd(\n    observation: ArrayLike,\n    shape: ArrayLike,\n    /,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the generalised Pareto distribution (GPD).</p> <p>This score is equivalent to the negative log likelihood of the GPD</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>shape</code> <code>ArrayLike</code> <p>Shape parameter of the forecast GPD distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast GPD distribution.</p> <code>0.0</code> <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast GPD distribution.</p> <code>1.0</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between obs and GPD(shape, location, scale).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_gpd(0.3, 0.9)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_hypergeometric","title":"scoringrules.logs_hypergeometric","text":"<pre><code>logs_hypergeometric(\n    observation: ArrayLike,\n    m: ArrayLike,\n    n: ArrayLike,\n    k: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the hypergeometric distribution.</p> <p>This score is equivalent to the negative log likelihood of the hypergeometric distribution</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>m</code> <code>ArrayLike</code> <p>Number of success states in the population.</p> required <code>n</code> <code>ArrayLike</code> <p>Number of failure states in the population.</p> required <code>k</code> <code>ArrayLike</code> <p>Number of draws, without replacement. Must be in 0, 1, ..., m + n.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between obs and Hypergeometric(m, n, k).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_hypergeometric(5, 7, 13, 12)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_laplace","title":"scoringrules.logs_laplace","text":"<pre><code>logs_laplace(\n    observation: ArrayLike,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the Laplace distribution.</p> <p>This score is equivalent to the negative log likelihood of the Laplace distribution</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>Observed values.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast laplace distribution.</p> <code>0.0</code> <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast laplace distribution. The LS between obs and Laplace(location, scale).</p> <code>1.0</code>"},{"location":"api/logarithmic/#scoringrules.logs_loglaplace","title":"scoringrules.logs_loglaplace","text":"<pre><code>logs_loglaplace(\n    observation: ArrayLike,\n    locationlog: ArrayLike,\n    scalelog: ArrayLike,\n    *,\n    backend: Backend = None\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the log-Laplace distribution.</p> <p>This score is equivalent to the negative log likelihood of the log-Laplace distribution</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>Observed values.</p> required <code>locationlog</code> <code>ArrayLike</code> <p>Location parameter of the forecast log-laplace distribution.</p> required <code>scalelog</code> <code>ArrayLike</code> <p>Scale parameter of the forecast log-laplace distribution.</p> required <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between obs and Loglaplace(locationlog, scalelog).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_loglaplace(3.0, 0.1, 0.9)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_logistic","title":"scoringrules.logs_logistic","text":"<pre><code>logs_logistic(\n    observation: ArrayLike,\n    mu: ArrayLike,\n    sigma: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the logistic distribution.</p> <p>This score is equivalent to the negative log likelihood of the logistic distribution</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <p>Observed values.</p> required <code>mu</code> <code>ArrayLike</code> <p>Location parameter of the forecast logistic distribution.</p> required <code>sigma</code> <code>ArrayLike</code> <p>Scale parameter of the forecast logistic distribution.</p> required <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS for the Logistic(mu, sigma) forecasts given the observations.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_logistic(0.0, 0.4, 0.1)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_loglogistic","title":"scoringrules.logs_loglogistic","text":"<pre><code>logs_loglogistic(\n    observation: ArrayLike,\n    mulog: ArrayLike,\n    sigmalog: ArrayLike,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the log-logistic distribution.</p> <p>This score is equivalent to the negative log likelihood of the log-logistic distribution</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>mulog</code> <code>ArrayLike</code> <p>Location parameter of the log-logistic distribution.</p> required <code>sigmalog</code> <code>ArrayLike</code> <p>Scale parameter of the log-logistic distribution.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between obs and Loglogis(mulog, sigmalog).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_loglogistic(3.0, 0.1, 0.9)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_lognormal","title":"scoringrules.logs_lognormal","text":"<pre><code>logs_lognormal(\n    observation: ArrayLike,\n    mulog: ArrayLike,\n    sigmalog: ArrayLike,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the log-normal distribution.</p> <p>This score is equivalent to the negative log likelihood of the log-normal distribution</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>mulog</code> <code>ArrayLike</code> <p>Mean of the normal underlying distribution.</p> required <code>sigmalog</code> <code>ArrayLike</code> <p>Standard deviation of the underlying normal distribution.</p> required <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between Lognormal(mu, sigma) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_lognormal(0.0, 0.4, 0.1)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_mixnorm","title":"scoringrules.logs_mixnorm","text":"<pre><code>logs_mixnorm(\n    observation: ArrayLike,\n    m: ArrayLike,\n    s: ArrayLike,\n    /,\n    w: ArrayLike = None,\n    axis: ArrayLike = -1,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score for a mixture of normal distributions.</p> <p>This score is equivalent to the negative log likelihood of the normal mixture distribution</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>m</code> <code>ArrayLike</code> <p>Means of the component normal distributions.</p> required <code>s</code> <code>ArrayLike</code> <p>Standard deviations of the component normal distributions.</p> required <code>w</code> <code>ArrayLike</code> <p>Non-negative weights assigned to each component.</p> <code>None</code> <code>axis</code> <code>ArrayLike</code> <p>The axis corresponding to the mixture components. Default is the last axis.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between MixNormal(m, s) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_mixnormal(0.0, [0.1, -0.3, 1.0], [0.4, 2.1, 0.7], [0.1, 0.2, 0.7])\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_negbinom","title":"scoringrules.logs_negbinom","text":"<pre><code>logs_negbinom(\n    observation: ArrayLike,\n    n: ArrayLike,\n    /,\n    prob: ArrayLike | None = None,\n    *,\n    mu: ArrayLike | None = None,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the negative binomial distribution.</p> <p>This score is equivalent to the negative log likelihood of the negative binomial distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>n</code> <code>ArrayLike</code> <p>Size parameter of the forecast negative binomial distribution.</p> required <code>prob</code> <code>ArrayLike | None</code> <p>Probability parameter of the forecast negative binomial distribution.</p> <code>None</code> <code>mu</code> <code>ArrayLike | None</code> <p>Mean of the forecast negative binomial distribution.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between NegBinomial(n, prob) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_negbinom(2, 5, 0.5)\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>If both <code>prob</code> and <code>mu</code> are provided, or if neither is provided.</p>"},{"location":"api/logarithmic/#scoringrules.logs_normal","title":"scoringrules.logs_normal","text":"<pre><code>logs_normal(\n    observation: ArrayLike,\n    mu: ArrayLike,\n    sigma: ArrayLike,\n    /,\n    *,\n    negative: bool = True,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the logarithmic score (LS) for the normal distribution.</p> <p>This score is equivalent to the (negative) log likelihood (if <code>negative = True</code>)</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>mu</code> <code>ArrayLike</code> <p>Mean of the forecast normal distribution.</p> required <code>sigma</code> <code>ArrayLike</code> <p>Standard deviation of the forecast normal distribution.</p> required <code>backend</code> <code>Backend</code> <p>The backend used for computations.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>Array</code> <p>The LS between Normal(mu, sigma) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_normal(0.0, 0.4, 0.1)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_2pnormal","title":"scoringrules.logs_2pnormal","text":"<pre><code>logs_2pnormal(\n    observation: ArrayLike,\n    scale1: ArrayLike,\n    scale2: ArrayLike,\n    location: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the two-piece normal distribution.</p> <p>This score is equivalent to the negative log likelihood of the two-piece normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <p>The observed values.</p> required <code>scale1</code> <code>ArrayLike</code> <p>Scale parameter of the lower half of the forecast two-piece normal distribution.</p> required <code>scale2</code> <code>ArrayLike</code> <p>Scale parameter of the upper half of the forecast two-piece normal distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast two-piece normal distribution.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between 2pNormal(scale1, scale2, location) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_2pnormal(0.0, 0.4, 2.0, 0.1)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_poisson","title":"scoringrules.logs_poisson","text":"<pre><code>logs_poisson(\n    observation: ArrayLike,\n    mean: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the Poisson distribution.</p> <p>This score is equivalent to the negative log likelihood of the Poisson distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>mean</code> <code>ArrayLike</code> <p>Mean parameter of the forecast poisson distribution.</p> required <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between Pois(mean) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_poisson(1, 2)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_t","title":"scoringrules.logs_t","text":"<pre><code>logs_t(\n    observation: ArrayLike,\n    df: ArrayLike,\n    /,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the Student's t distribution.</p> <p>This score is equivalent to the negative log likelihood of the t distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>df</code> <code>ArrayLike</code> <p>Degrees of freedom parameter of the forecast t distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast t distribution.</p> <code>0.0</code> <code>sigma</code> <p>Scale parameter of the forecast t distribution.</p> required <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between t(df, location, scale) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_t(0.0, 0.1, 0.4, 0.1)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_tlogistic","title":"scoringrules.logs_tlogistic","text":"<pre><code>logs_tlogistic(\n    observation: ArrayLike,\n    location: ArrayLike,\n    scale: ArrayLike,\n    /,\n    lower: ArrayLike = float(\"-inf\"),\n    upper: ArrayLike = float(\"inf\"),\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the truncated logistic distribution.</p> <p>This score is equivalent to the negative log likelihood of the truncated logistic distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast distribution.</p> required <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast distribution.</p> required <code>lower</code> <code>ArrayLike</code> <p>Lower boundary of the truncated forecast distribution.</p> <code>float('-inf')</code> <code>upper</code> <code>ArrayLike</code> <p>Upper boundary of the truncated forecast distribution.</p> <code>float('inf')</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between tLogistic(location, scale, lower, upper) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_tlogistic(0.0, 0.1, 0.4, -1.0, 1.0)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_tnormal","title":"scoringrules.logs_tnormal","text":"<pre><code>logs_tnormal(\n    observation: ArrayLike,\n    location: ArrayLike,\n    scale: ArrayLike,\n    /,\n    lower: ArrayLike = float(\"-inf\"),\n    upper: ArrayLike = float(\"inf\"),\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the truncated normal distribution.</p> <p>This score is equivalent to the negative log likelihood of the truncated normal distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast distribution.</p> required <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast distribution.</p> required <code>lower</code> <code>ArrayLike</code> <p>Lower boundary of the truncated forecast distribution.</p> <code>float('-inf')</code> <code>upper</code> <code>ArrayLike</code> <p>Upper boundary of the truncated forecast distribution.</p> <code>float('inf')</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between tNormal(location, scale, lower, upper) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_tnormal(0.0, 0.1, 0.4, -1.0, 1.0)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_tt","title":"scoringrules.logs_tt","text":"<pre><code>logs_tt(\n    observation: ArrayLike,\n    df: ArrayLike,\n    /,\n    location: ArrayLike = 0.0,\n    scale: ArrayLike = 1.0,\n    lower: ArrayLike = float(\"-inf\"),\n    upper: ArrayLike = float(\"inf\"),\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the truncated Student's t distribution.</p> <p>This score is equivalent to the negative log likelihood of the truncated t distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>df</code> <code>ArrayLike</code> <p>Degrees of freedom parameter of the forecast distribution.</p> required <code>location</code> <code>ArrayLike</code> <p>Location parameter of the forecast distribution.</p> <code>0.0</code> <code>scale</code> <code>ArrayLike</code> <p>Scale parameter of the forecast distribution.</p> <code>1.0</code> <code>lower</code> <code>ArrayLike</code> <p>Lower boundary of the truncated forecast distribution.</p> <code>float('-inf')</code> <code>upper</code> <code>ArrayLike</code> <p>Upper boundary of the truncated forecast distribution.</p> <code>float('inf')</code> <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between tt(df, location, scale, lower, upper) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_tt(0.0, 2.0, 0.1, 0.4, -1.0, 1.0)\n</code></pre>"},{"location":"api/logarithmic/#scoringrules.logs_uniform","title":"scoringrules.logs_uniform","text":"<pre><code>logs_uniform(\n    observation: ArrayLike,\n    min: ArrayLike,\n    max: ArrayLike,\n    /,\n    *,\n    backend: Backend = None,\n) -&gt; ArrayLike\n</code></pre> <p>Compute the logarithmic score (LS) for the uniform distribution.</p> <p>This score is equivalent to the negative log likelihood of the uniform distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observation</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>min</code> <code>ArrayLike</code> <p>Lower bound of the forecast uniform distribution.</p> required <code>max</code> <code>ArrayLike</code> <p>Upper bound of the forecast uniform distribution.</p> required <p>Returns:</p> Name Type Description <code>score</code> <code>ArrayLike</code> <p>The LS between U(min, max, lmass, umass) and obs.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.logs_uniform(0.4, 0.0, 1.0)\n</code></pre>"},{"location":"api/logarithmic/#conditional-and-censored-likelihood-score","title":"Conditional and Censored Likelihood Score","text":""},{"location":"api/logarithmic/#scoringrules.clogs_ensemble","title":"scoringrules.clogs_ensemble","text":"<pre><code>clogs_ensemble(\n    observations: ArrayLike,\n    forecasts: Array,\n    /,\n    a: ArrayLike = float(\"-inf\"),\n    b: ArrayLike = float(\"inf\"),\n    axis: int = -1,\n    *,\n    bw: ArrayLike = None,\n    cens: bool = True,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Estimate the conditional and censored likelihood score for an ensemble forecast.</p> <p>The conditional and censored likelihood scores are introduced by Diks et al. (2011):</p> <p>The weight function is an indicator function of the form \\(w(z) = 1\\{a &lt; z &lt; b\\}\\).</p> <p>The ensemble forecast is converted to a mixture of normal distributions using Gaussian kernel density estimation. The score is then calculated for this smoothed distribution.</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the last axis.</p> required <code>a</code> <code>ArrayLike</code> <p>The lower bound in the weight function.</p> <code>float('-inf')</code> <code>b</code> <code>ArrayLike</code> <p>The upper bound in the weight function.</p> <code>float('inf')</code> <code>axis</code> <code>int</code> <p>The axis corresponding to the ensemble. Default is the last axis.</p> <code>-1</code> <code>bw</code> <code>ArrayLike</code> <p>The bandwidth parameter for each forecast ensemble. If not given, estimated using Silverman's rule of thumb.</p> <code>None</code> <code>cens</code> <code>Boolean</code> <p>Boolean specifying whether to return the conditional ('cens = False') or the censored likelihood score ('cens = True').</p> <code>True</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>score</code> <code>Array</code> <p>The CoLS or CeLS between the forecast ensemble and obs for the chosen weight parameters.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.clogs_ensemble(obs, pred, -1.0, 1.0)\n</code></pre>"},{"location":"api/quantile/","title":"Quantile score","text":""},{"location":"api/quantile/#scoringrules.quantile_score","title":"scoringrules.quantile_score","text":"<pre><code>quantile_score(\n    obs: ArrayLike,\n    fct: ArrayLike,\n    alpha: ArrayLike,\n    backend: Backend | None = None,\n) -&gt; Array\n</code></pre> <p>Compute the quantile score for a given quantile level.</p> <p>The quantile score (Koenker, R. and G. Bassett, 1978) is defined as</p> \\[     S_{\\alpha}(q_{\\alpha}, y) = \\begin{cases}     (1 - \\alpha) (q_{\\alpha} - y), &amp; \\text{if } y \\leq q_{\\alpha}, \\\\     \\alpha (y - q_{\\alpha}), &amp; \\text{if } y &gt; q_{\\alpha}.     \\end{cases} \\] <p>where \\(y\\) is the observed value and \\(q_{\\alpha}\\) is the predicted value at the \\(\\alpha\\) quantile level.</p> <p>Parameters:</p> Name Type Description Default <code>obs</code> <code>ArrayLike</code> <p>The observed values.</p> required <code>fct</code> <code>ArrayLike</code> <p>The forecast values.</p> required <code>alpha</code> <code>ArrayLike</code> <p>The quantile level.</p> required <p>Returns:</p> Name Type Description <code>score</code> <code>Array</code> <p>The quantile score.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import scoringrules as sr\n&gt;&gt;&gt; sr.quantile_score(0.3, 0.5, 0.2)\n0.16\n</code></pre> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the quantile level is not between 0 and 1.</p>"},{"location":"api/variogram/","title":"Variogram Score","text":"<p>The varigoram score (VS) is a scoring rule for evaluating multivariate probabilistic forecasts. It is defined as</p> \\[\\text{VS}_{p}(F, \\mathbf{y})= \\sum_{i=1}^{d} \\sum_{j=1}^{d} \\left( \\mathbb{E} | X_{i} - X_{j} |^{p} - | y_{i} - y_{j} |^{p} \\right)^{2}, \\] <p>where \\(p &gt; 0\\), \\(\\mathbf{y} = (y_{1}, \\dots, y_{d}) \\in \\mathbb{R}^{d}\\) is the multivariate observation (\\(d &gt; 1\\)), and \\(\\mathbf{X} = (X_{1}, \\dots, X_{d})\\) is a random vector that follows the multivariate forecast distribution \\(F\\) (Scheuerer and Hamill, 2015)<sup>1</sup>. The exponent \\(p\\) is typically chosen to be 0.5 or 1.</p> <p>The variogram score is less sensitive to marginal forecast performance than the energy score, and Scheuerer and Hamill (2015) argue that it should therefore be more sensitive to errors in the forecast's dependence structure.</p> <p>While multivariate probabilistic forecasts could belong to a parametric family of distributions, such as a multivariate normal distribution, it is more common in practice that these forecasts are ensemble forecasts; that is, the forecast is comprised of a predictive sample \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\), where each ensemble member \\(\\mathbf{x}_{i} = (x_{i, 1}, \\dots, x_{i, d}) \\in \\R^{d}\\) for \\(i = 1, \\dots, M\\).</p> <p>In this case, the expectation in the definition of the variogram score can be replaced by a sample mean over the ensemble members, yielding the following representation of the variogram score when evaluating an ensemble forecast \\(F_{ens}\\) with \\(M\\) members.</p> <p></p> Weighted versions <p>It is often the case that certain outcomes are of more interest than others when evaluating forecast performance. These outcomes can be emphasised by employing weighted scoring rules. Weighted scoring rules typically introduce a weight function into conventional scoring rules, and users can choose the weight function depending on what outcomes they want to emphasise. Allen et al. (2022)<sup>2</sup>  introduced three weighted versions of the variogram score. These are all available in <code>scoringrules</code>.</p> <p>Firstly, the outcome-weighted variogram score (see also Holzmann and Klar (2014)<sup>3</sup>) is defined as</p> \\[\\text{owVS}_{p}(F, \\mathbf{y}; w) = \\frac{1}{\\bar{w}} \\mathbb{E} [ \\rho_{p}(\\mathbf{X}, \\mathbf{y}) w(\\mathbf{X}) w(\\mathbf{y}) ] - \\frac{1}{2 \\bar{w}^{2}} \\mathbb{E} [ \\rho_{p}(\\mathbf{X}, \\mathbf{X}^{\\prime}) w(\\mathbf{X}) w(\\mathbf{X}^{\\prime}) w(\\mathbf{y}) ], \\] <p>where</p> \\[ \\rho_{p}(\\mathbf{x}, \\mathbf{z}) = \\sum_{i=1}^{d} \\sum_{j=1}^{d} \\left( |x_{i} - x_{j}|^{p} - |z_{i} - z_{j}|^{p} \\right)^{2}, \\] <p>for \\(\\mathbf{x} = (x_{1}, \\dots, x_{d}) \\in \\mathbb{R}^{d}\\) and \\(\\mathbf{z} = (z_{1}, \\dots, z_{d}) \\in \\mathbb{R}^{d}\\).</p> <p>Here, \\(w : \\mathbb{R}^{d} \\to [0, \\infty)\\) is the non-negative weight function used to target particular multivariate outcomes, and \\(\\bar{w} = \\mathbb{E}[w(X)]\\). As before, \\(\\mathbf{X}, \\mathbf{X}^{\\prime} \\sim F\\) are independent.</p> <p></p> <p>Secondly, Allen et al. (2022) introduced the threshold-weighted variogram score as</p> \\[\\text{twVS}_{p}(F, \\mathbf{y}; v)= \\sum_{i=1}^{d} \\sum_{j=1}^{d} \\left( \\mathbb{E} | v(\\mathbf{X})_{i} - v(\\mathbf{X})_{j} |^{p} - | v(\\mathbf{y})_{i} - v(\\mathbf{y})_{j} |^{p} \\right)^{2}, \\] <p>where \\(v : \\mathbb{R}^{d} \\to \\mathbb{R}^{d}\\) is a so-called chaining function, so that \\(v(\\mathbf{X}) = (v(\\mathbf{X})_{1}, \\dots, v(\\mathbf{X})_{d}) \\in \\mathbb{R}^{d}\\). The threshold-weighted variogram score transforms the forecasts and observations according to the chaining function \\(v\\), prior to calculating the unweighted variogram score. Choosing a chaining function is generally more difficult than choosing a weight function when emphasising particular outcomes.</p> <p></p> <p>As an alternative, the vertically re-scaled variogram score is defined as</p> \\[\\text{vrVS}_{p}(F, \\mathbf{y}; w) = \\mathbb{E} [ \\rho_{p}(\\mathbf{X}, \\mathbf{y}) w(\\mathbf{X}) w(\\mathbf{y}) ] - \\frac{1}{2} \\mathbb{E} [ \\rho_{p}(\\mathbf{X}, \\mathbf{X}^{\\prime}) w(\\mathbf{X}) w(\\mathbf{X}^{\\prime}) ] + \\left( \\mathbb{E} [ \\rho_{p} ( \\mathbf{X}, \\mathbf{x}_{0} ) w(\\mathbf{X}) ] - \\rho_{p} ( \\mathbf{y}, \\mathbf{x}_{0}) w(\\mathbf{y}) \\right) \\left(\\mathbb{E}[w(\\mathbf{X})] - w(\\mathbf{y}) \\right), \\] <p>where \\(w\\) and \\(\\rho_{p}\\) are as defined above, and \\(\\mathbf{x}_{0} \\in \\mathbb{R}^{d}\\). Typically, \\(\\mathbf{x}_{0}\\) is chosen to be the zero vector.</p> <p></p> <p>Each of these weighted variogram scores targets particular outcomes in a different way. Further details regarding the differences between these scoring rules, as well as choices for the weight and chaining functions, can be found in Allen et al. (2022). The weighted variogram scores can easily be computed for ensemble forecasts by replacing the expectations with sample means over the ensemble members.</p> <ol> <li> <p>Michael Scheuerer and Thomas M. Hamill. Variogram-Based Proper Scoring Rules for Probabilistic Forecasts of Multivariate Quantities. Monthly Weather Review, 2015. URL: https://journals.ametsoc.org/view/journals/mwre/143/4/mwr-d-14-00269.1.xml, doi:10.1175/MWR-D-14-00269.1.\u00a0\u21a9</p> </li> <li> <p>Sam Allen, David Ginsbourger, and Johanna Ziegel. Evaluating forecasts for high-impact events using transformed kernel scores. arXiv preprint arXiv:2202.12732, 2022.\u00a0\u21a9</p> </li> <li> <p>Hajo Holzmann and Bernhard Klar. Focusing on regions of interest in forecast evaluation. The Annals of Applied Statistics, 11:2404\u20132431, 2017.\u00a0\u21a9</p> </li> </ol>"},{"location":"api/variogram/#scoringrules.variogram_score","title":"scoringrules.variogram_score","text":"<pre><code>variogram_score(\n    observations: Array,\n    forecasts: Array,\n    /,\n    m_axis: int = -2,\n    v_axis: int = -1,\n    *,\n    p: float = 1.0,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Variogram Score for a finite multivariate ensemble.</p> <p>For a \\(D\\)-variate ensemble the Variogram Score (Sheuerer and Hamill, 2015) of order \\(p\\) is expressed as</p> \\[\\text{VS}_{p}(F_{ens}, \\mathbf{y})= \\sum_{i=1}^{d} \\sum_{j=1}^{d} \\left( \\frac{1}{M} \\sum_{m=1}^{M} | x_{m,i} - x_{m,j} |^{p} - | y_{i} - y_{j} |^{p} \\right)^{2}. \\] <p>where \\(\\mathbf{X}\\) and \\(\\mathbf{X'}\\) are independently sampled ensembles from from \\(F\\).</p> <p>Parameters:</p> Name Type Description Default <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the second last axis and the variables dimension by the last axis.</p> required <code>observations</code> <code>Array</code> <p>The observed values, where the variables dimension is by default the last axis.</p> required <code>p</code> <code>float</code> <p>The order of the Variogram Score. Typical values are 0.5, 1.0 or 2.0. Defaults to 1.0.</p> <code>1.0</code> <code>m_axis</code> <code>int</code> <p>The axis corresponding to the ensemble dimension. Defaults to -2.</p> <code>-2</code> <code>v_axis</code> <code>int</code> <p>The axis corresponding to the variables dimension. Defaults to -1.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>variogram_score</code> <code>Array</code> <p>The computed Variogram Score.</p>"},{"location":"api/variogram/#scoringrules.owvariogram_score","title":"scoringrules.owvariogram_score","text":"<pre><code>owvariogram_score(\n    observations: Array,\n    forecasts: Array,\n    w_func: tp.Callable,\n    /,\n    m_axis: int = -2,\n    v_axis: int = -1,\n    *,\n    p: float = 1.0,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Outcome-Weighted Variogram Score (owVS) for a finite multivariate ensemble.</p> <p>Computation is performed using the ensemble representation of the owVS in Allen et al. (2022):</p> \\[ \\begin{split}     \\mathrm{owVS}(F_{ens}, \\mathbf{y}) = &amp; \\frac{1}{M \\bar{w}} \\sum_{m=1}^{M} \\sum_{i,j=1}^{D}(|y_{i} - y_{j}|^{p} - |x_{m,i} - x_{m,j}|^{p})^{2} w(\\mathbf{x}_{m}) w(\\mathbf{y}) \\\\         &amp; - \\frac{1}{2 M^{2} \\bar{w}^{2}} \\sum_{k,m=1}^{M} \\sum_{i,j=1}^{D} \\left( |x_{k,i} - x_{k,j}|^{p} - |x_{m,i} - x_{m,j}|^{p} \\right)^{2} w(\\mathbf{x}_{k}) w(\\mathbf{x}_{m}) w(\\mathbf{y}), \\end{split} \\] <p>where \\(F_{ens}\\) is the ensemble forecast \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\) with \\(M\\) members, \\(w\\) is the chosen weight function, and \\(\\bar{w} = \\sum_{m=1}^{M}w(\\mathbf{x}_{m})/M\\).</p> <p>Parameters:</p> Name Type Description Default <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the second last axis and the variables dimension by the last axis.</p> required <code>observations</code> <code>Array</code> <p>The observed values, where the variables dimension is by default the last axis.</p> required <code>p</code> <code>float</code> <p>The order of the Variogram Score. Typical values are 0.5, 1.0 or 2.0. Defaults to 1.0.</p> <code>1.0</code> <code>w_func</code> <code>Callable</code> <p>Weight function used to emphasise particular outcomes.</p> required <code>m_axis</code> <code>int</code> <p>The axis corresponding to the ensemble dimension. Defaults to -2.</p> <code>-2</code> <code>v_axis</code> <code>int</code> <p>The axis corresponding to the variables dimension. Defaults to -1.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>owvariogram_score</code> <code>ArrayLike of shape (...)</code> <p>The computed Outcome-Weighted Variogram Score.</p>"},{"location":"api/variogram/#scoringrules.twvariogram_score","title":"scoringrules.twvariogram_score","text":"<pre><code>twvariogram_score(\n    observations: Array,\n    forecasts: Array,\n    v_func: tp.Callable,\n    /,\n    m_axis: int = -2,\n    v_axis: int = -1,\n    *,\n    p: float = 1.0,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Threshold-Weighted Variogram Score (twVS) for a finite multivariate ensemble.</p> <p>Computation is performed using the ensemble representation of the twVS in Allen et al. (2022):</p> \\[     \\mathrm{twVS}(F_{ens}, \\mathbf{y}) = \\sum_{i,j=1}^{D}(|v(\\mathbf{y})_i - v(\\mathbf{y})_{j}|^{p} - \\frac{1}{M} \\sum_{m=1}^{M}|v(\\mathbf{x}_{m})_{i} - v(\\mathbf{x}_{m})_{j}|^{p})^{2}, \\] <p>where \\(F_{ens}\\) is the ensemble forecast \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\) with \\(M\\) members, and \\(v\\) is the chaining function used to target particular outcomes.</p> <p>Parameters:</p> Name Type Description Default <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the second last axis and the variables dimension by the last axis.</p> required <code>observations</code> <code>Array</code> <p>The observed values, where the variables dimension is by default the last axis.</p> required <code>p</code> <code>float</code> <p>The order of the Variogram Score. Typical values are 0.5, 1.0 or 2.0. Defaults to 1.0.</p> <code>1.0</code> <code>v_func</code> <code>Callable</code> <p>Chaining function used to emphasise particular outcomes.</p> required <code>m_axis</code> <code>int</code> <p>The axis corresponding to the ensemble dimension. Defaults to -2.</p> <code>-2</code> <code>v_axis</code> <code>int</code> <p>The axis corresponding to the variables dimension. Defaults to -1.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>twvariogram_score</code> <code>ArrayLike of shape (...)</code> <p>The computed Threshold-Weighted Variogram Score.</p>"},{"location":"api/variogram/#scoringrules.vrvariogram_score","title":"scoringrules.vrvariogram_score","text":"<pre><code>vrvariogram_score(\n    observations: Array,\n    forecasts: Array,\n    w_func: tp.Callable,\n    /,\n    m_axis: int = -2,\n    v_axis: int = -1,\n    *,\n    p: float = 1.0,\n    backend: Backend = None,\n) -&gt; Array\n</code></pre> <p>Compute the Vertically Re-scaled Variogram Score (vrVS) for a finite multivariate ensemble.</p> <p>Computation is performed using the ensemble representation of the vrVS in Allen et al. (2022):</p> \\[ \\begin{split}     \\mathrm{vrVS}(F_{ens}, \\mathbf{y}) = &amp; \\frac{1}{M} \\sum_{m=1}^{M} \\sum_{i,j=1}^{D}(|y_{i} - y_{j}|^{p} - |x_{m,i} - x_{m,j}|^{p})^{2} w(\\mathbf{x}_{m}) w(\\mathbf{y}) \\\\         &amp; - \\frac{1}{2 M^{2}} \\sum_{k,m=1}^{M} \\sum_{i,j=1}^{D} \\left( |x_{k,i} - x_{k,j}|^{p} - |x_{m,i} - x_{m,j}|^{p} \\right)^{2} w(\\mathbf{x}_{k}) w(\\mathbf{x}_{m})) \\\\         &amp; + \\left( \\frac{1}{M} \\sum_{m = 1}^{M} \\sum_{i,j=1}^{D}(|x_{m,i} - x_{m,j}|^{p} w(\\mathbf{x}_{m}) - \\sum_{i,j=1}^{D}(|y_{i} - y_{j}|^{p} w(\\mathbf{y}) \\right) \\left( \\frac{1}{M} \\sum_{m = 1}^{M} w(\\mathbf{x}_{m}) - w(\\mathbf{y}) \\right), \\end{split} \\] <p>where \\(F_{ens}\\) is the ensemble forecast \\(\\mathbf{x}_{1}, \\dots, \\mathbf{x}_{M}\\) with \\(M\\) members, \\(w\\) is the chosen weight function, and \\(\\bar{w} = \\sum_{m=1}^{M}w(\\mathbf{x}_{m})/M\\).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>Array</code> <p>The observed values, where the variables dimension is by default the last axis.</p> required <code>forecasts</code> <code>Array</code> <p>The predicted forecast ensemble, where the ensemble dimension is by default represented by the second last axis and the variables dimension by the last axis.</p> required <code>p</code> <code>float</code> <p>The order of the Variogram Score. Typical values are 0.5, 1.0 or 2.0. Defaults to 1.0.</p> <code>1.0</code> <code>w_func</code> <code>Callable</code> <p>Weight function used to emphasise particular outcomes.</p> required <code>m_axis</code> <code>int</code> <p>The axis corresponding to the ensemble dimension. Defaults to -2.</p> <code>-2</code> <code>v_axis</code> <code>int</code> <p>The axis corresponding to the variables dimension. Defaults to -1.</p> <code>-1</code> <code>backend</code> <code>Backend</code> <p>The name of the backend used for computations. Defaults to 'numba' if available, else 'numpy'.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>vrvariogram_score</code> <code>ArrayLike of shape (...)</code> <p>The computed Vertically Re-scaled Variogram Score.</p>"},{"location":"api/visualization/","title":"Visualization","text":"<p>Scoring rules alone are not enough for a thorough evaluation of probabilistic forecasts. Visualizations can be used as a complement.</p>"},{"location":"api/visualization/#scoringrules.visualization.reliability_diagram","title":"scoringrules.visualization.reliability_diagram","text":"<pre><code>reliability_diagram(\n    observations: np.ndarray,\n    forecasts: np.ndarray,\n    /,\n    uncertainty_band: (\n        tp.Literal[\"confidence\", \"consistency\"] | None\n    ) = \"consistency\",\n    n_bootstrap: int = 100,\n    alpha: float = 0.05,\n    ax: plt.Axes = None,\n) -&gt; plt.Axes\n</code></pre> <p>Plot the reliability diagram of a set of predictions.</p> <p>CORP: Consistent, Optimally binned, Reproducible, PAV-algorithm based reliability diagram from Dimitriadis et al. (2021).</p> <p>Parameters:</p> Name Type Description Default <code>observations</code> <code>ndarray</code> <p>The observed outcomes, either 0 or 1.</p> required <code>forecasts</code> <code>ndarray</code> <p>Forecasted probabilities between 0 and 1.</p> required <code>uncertainty_band</code> <code>Literal['confidence', 'consistency'] | None</code> <p>The type of uncertainty band to plot, which can be either <code>'confidence'</code> or <code>'consistency'</code>band. If None, no uncertainty band is plotted.</p> <code>'consistency'</code> <code>n_bootstrap</code> <code>int</code> <p>The number of bootstrap samples to use for the uncertainty band.</p> <code>100</code> <code>alpha</code> <code>float</code> <p>The confidence level for the uncertainty band.</p> <code>0.05</code> <p>Returns:</p> Name Type Description <code>ax</code> <code>Axes</code> <p>The CORP reliability diagram plot.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from scoringrules.visualization import reliability_diagram\n&gt;&gt;&gt; x = np.random.uniform(0, 1, 1024)\n&gt;&gt;&gt; y = np.random.binomial(1, np.sqrt(x), 1024)\n&gt;&gt;&gt; ax = reliability_diagram(y, x)\n</code></pre>"},{"location":"extras/estimators/","title":"Estimators","text":""},{"location":"extras/estimators/#integral-form-int","title":"Integral form (INT)","text":"<p>The numerical approximation of the cumulative integral over the finite ensemble.</p> \\[ \\text{CRPS}_{\\text{INT}}(M, y) = \\int_{\\mathbb{R}} \\left[ \\frac{1}{M} \\sum_{i=1}^M \\mathbb{1}\\{x_i \\le x \\} - \\mathbb{1}\\{y \\le x\\}  \\right] ^2 dx \\] <p>Runs with \\(O(m\\cdot\\mathrm{log}m)\\) complexity, including the sorting of the ensemble.</p>"},{"location":"extras/estimators/#energy-form-nrg","title":"Energy form (NRG)","text":"<p>Introduced by Gneiting and Raftery (2007)<sup>1</sup>:</p> \\[ \\text{CRPS}_{\\text{NRG}}(M, y) = \\frac{1}{M} \\sum_{i=1}^{M}|x_i - y| - \\frac{1}{2 M^2}\\sum_{i,j=1}^{M}|x_i - x_j|\\] <p>It is called the \"energy form\" because it is the one-dimensional case of the Energy Score.</p> <p>Runs with \\(O(m^2)\\) complexity.</p>"},{"location":"extras/estimators/#quantile-decomposition-form-qd","title":"Quantile decomposition form (QD)","text":"<p>Introduced by Jordan (2016)<sup>2</sup>:</p> \\[\\mathrm{CRPS}_{\\mathrm{QD}}(M, y) = \\frac{2}{M^2} \\sum_{i=1}^{M}(x_i - y)\\left[M\\mathbb{1}\\{y \\le x_i\\} - i + \\frac{1}{2} \\right]\\] <p>Runs with \\(O(m\\cdot\\mathrm{log}m)\\) complexity, including the sorting of the ensemble.</p>"},{"location":"extras/estimators/#probability-weighted-moment-form-pwm","title":"Probability weighted moment form (PWM)","text":"<p>Introduced by Taillardat et al. (2016)<sup>3</sup>:</p> \\[\\mathrm{CRPS}_{\\mathrm{NRG}}(M, y) = \\frac{1}{M} \\sum_{i=1}^{M}|x_i - y| + \\hat{\\beta_0} - 2\\hat{\\beta_1},\\] <p>where \\(\\hat{\\beta_0} = \\frac{1}{M} \\sum_{i=1}^{M}x_i\\) and \\(\\hat{\\beta_1} = \\frac{1}{M(M-1)} \\sum_{i=1}^{M}(i - 1)x_i\\). Runs with \\(O(m\\cdot\\mathrm{log}m)\\) complexity, including the sorting of the ensemble.</p> <ol> <li> <p>Tilmann Gneiting and Adrian E Raftery. Strictly Proper Scoring Rules, Prediction, and Estimation. Journal of the American Statistical Association, 2007. URL: https://doi.org/10.1198/016214506000001437, doi:10.1198/016214506000001437.\u00a0\u21a9</p> </li> <li> <p>Alexander Jordan. Facets of forecast evaluation. PhD thesis, Karlsruher Institut f\u00fcr Technologie (KIT), 2016. doi:10.5445/IR/1000063629.\u00a0\u21a9</p> </li> <li> <p>Maxime Taillardat, Olivier Mestre, Micha\u00ebl Zamo, and Philippe Naveau. Calibrated Ensemble Forecasts Using Quantile Regression Forests and Ensemble Model Output Statistics. Monthly Weather Review, 2016. URL: http://journals.ametsoc.org/doi/10.1175/MWR-D-15-0260.1, doi:10.1175/MWR-D-15-0260.1.\u00a0\u21a9</p> </li> </ol>"}]}